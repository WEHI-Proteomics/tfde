{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import pickle\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "percolator_df = pd.read_pickle('/Users/darylwilding-mcbride/Downloads/percolator_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['file_idx', 'scan', 'charge_x', 'spectrum precursor m/z',\n",
       "       'spectrum neutral mass', 'peptide mass', 'percolator score',\n",
       "       'percolator q-value', 'percolator PEP', 'total matches/spectrum',\n",
       "       'sequence', 'protein id', 'flanking aa', 'feature_id', 'charge_y',\n",
       "       'rt_apex', 'scan_apex', 'intensity', 'precursor_id',\n",
       "       'monoisotopic_mass', 'predicted_mass_error',\n",
       "       'recalibrated_monoisotopic_mass', 'recalibrated_monoisotopic_mz',\n",
       "       'percolator_idx', 'batch', 'human'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percolator_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the experiment-average for each sequence-charge\n",
    "experiment_sequences_l = []\n",
    "for group_name,group_df in percolator_df.groupby(['sequence','charge_x'], as_index=False):\n",
    "    sequence = group_name[0]\n",
    "    charge = group_name[1]\n",
    "    theoretical_mz = group_df.iloc[0]['spectrum precursor m/z']\n",
    "    experiment_average_scan = group_df.scan_apex.mean()\n",
    "    experiment_average_rt = group_df.rt_apex.mean()\n",
    "    experiment_sequences_l.append((sequence, charge, theoretical_mz, experiment_average_scan, experiment_average_rt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_sequences_df = pd.DataFrame(experiment_sequences_l, columns=['sequence','charge','theoretical_mz', 'experiment_average_scan', 'experiment_average_rt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>charge</th>\n",
       "      <th>theoretical_mz</th>\n",
       "      <th>experiment_average_scan</th>\n",
       "      <th>experiment_average_rt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAAAAAAAAPAAAATAPTTAATTAATAAQ</td>\n",
       "      <td>2</td>\n",
       "      <td>1184.1049</td>\n",
       "      <td>73.528889</td>\n",
       "      <td>604.371111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAAAAAAAAPAAAATAPTTAATTAATAAQ</td>\n",
       "      <td>3</td>\n",
       "      <td>789.7394</td>\n",
       "      <td>336.016667</td>\n",
       "      <td>609.890000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAAAAAAAVPSAGPAGPAPTSAAGR</td>\n",
       "      <td>2</td>\n",
       "      <td>1016.0286</td>\n",
       "      <td>159.998000</td>\n",
       "      <td>489.613333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAAAALSQQQSLQER</td>\n",
       "      <td>2</td>\n",
       "      <td>785.9075</td>\n",
       "      <td>496.325000</td>\n",
       "      <td>375.042500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAAAATVVPPMVGGPPFVGPVGFGPGDR</td>\n",
       "      <td>3</td>\n",
       "      <td>864.1171</td>\n",
       "      <td>706.957407</td>\n",
       "      <td>1039.716667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        sequence  charge  theoretical_mz  \\\n",
       "0  AAAAAAAAAPAAAATAPTTAATTAATAAQ       2       1184.1049   \n",
       "1  AAAAAAAAAPAAAATAPTTAATTAATAAQ       3        789.7394   \n",
       "2      AAAAAAAAVPSAGPAGPAPTSAAGR       2       1016.0286   \n",
       "3                AAAAALSQQQSLQER       2        785.9075   \n",
       "4   AAAAATVVPPMVGGPPFVGPVGFGPGDR       3        864.1171   \n",
       "\n",
       "   experiment_average_scan  experiment_average_rt  \n",
       "0                73.528889             604.371111  \n",
       "1               336.016667             609.890000  \n",
       "2               159.998000             489.613333  \n",
       "3               496.325000             375.042500  \n",
       "4               706.957407            1039.716667  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_sequences_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_sequences_l = []\n",
    "for group_name,group_df in percolator_df.groupby(['file_idx','sequence','charge_x'], as_index=False):\n",
    "    file_idx = group_name[0]\n",
    "    sequence = group_name[1]\n",
    "    charge = group_name[2]\n",
    "    run_average_mz = group_df.recalibrated_monoisotopic_mz.mean()\n",
    "    run_average_scan = group_df.scan_apex.mean()\n",
    "    run_average_rt = group_df.rt_apex.mean()\n",
    "    run_sequences_l.append((file_idx,sequence,charge,run_average_mz,run_average_scan,run_average_rt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_sequences_df = pd.DataFrame(run_sequences_l, columns=['file_idx','sequence','charge','run_average_mz','run_average_scan','run_average_rt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_idx</th>\n",
       "      <th>sequence</th>\n",
       "      <th>charge</th>\n",
       "      <th>run_average_mz</th>\n",
       "      <th>run_average_scan</th>\n",
       "      <th>run_average_rt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>AAAAAAAAAPAAAATAPTTAATTAATAAQ</td>\n",
       "      <td>2</td>\n",
       "      <td>1184.608396</td>\n",
       "      <td>74.015000</td>\n",
       "      <td>601.575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>AAAAAAAAVPSAGPAGPAPTSAAGR</td>\n",
       "      <td>2</td>\n",
       "      <td>1016.532319</td>\n",
       "      <td>156.406667</td>\n",
       "      <td>486.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>AAAAAWEEPSSGNGTAR</td>\n",
       "      <td>2</td>\n",
       "      <td>823.382064</td>\n",
       "      <td>535.310000</td>\n",
       "      <td>367.240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>AAAAPVTGPLADDPIQETITFDDFAK</td>\n",
       "      <td>3</td>\n",
       "      <td>892.112987</td>\n",
       "      <td>468.100000</td>\n",
       "      <td>997.180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>AAAEDVNVTFEDQQK</td>\n",
       "      <td>2</td>\n",
       "      <td>832.891998</td>\n",
       "      <td>485.630000</td>\n",
       "      <td>471.790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   file_idx                       sequence  charge  run_average_mz  \\\n",
       "0         0  AAAAAAAAAPAAAATAPTTAATTAATAAQ       2     1184.608396   \n",
       "1         0      AAAAAAAAVPSAGPAGPAPTSAAGR       2     1016.532319   \n",
       "2         0              AAAAAWEEPSSGNGTAR       2      823.382064   \n",
       "3         0     AAAAPVTGPLADDPIQETITFDDFAK       3      892.112987   \n",
       "4         0                AAAEDVNVTFEDQQK       2      832.891998   \n",
       "\n",
       "   run_average_scan  run_average_rt  \n",
       "0         74.015000         601.575  \n",
       "1        156.406667         486.690  \n",
       "2        535.310000         367.240  \n",
       "3        468.100000         997.180  \n",
       "4        485.630000         471.790  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_sequences_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(run_sequences_df, experiment_sequences_df, how='left', left_on=['sequence','charge'], right_on=['sequence','charge'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_idx</th>\n",
       "      <th>sequence</th>\n",
       "      <th>charge</th>\n",
       "      <th>run_average_mz</th>\n",
       "      <th>run_average_scan</th>\n",
       "      <th>run_average_rt</th>\n",
       "      <th>theoretical_mz</th>\n",
       "      <th>experiment_average_scan</th>\n",
       "      <th>experiment_average_rt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>AAAAAAAAAPAAAATAPTTAATTAATAAQ</td>\n",
       "      <td>2</td>\n",
       "      <td>1184.608396</td>\n",
       "      <td>74.015000</td>\n",
       "      <td>601.575</td>\n",
       "      <td>1184.1049</td>\n",
       "      <td>73.528889</td>\n",
       "      <td>604.371111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>AAAAAAAAVPSAGPAGPAPTSAAGR</td>\n",
       "      <td>2</td>\n",
       "      <td>1016.532319</td>\n",
       "      <td>156.406667</td>\n",
       "      <td>486.690</td>\n",
       "      <td>1016.0286</td>\n",
       "      <td>159.998000</td>\n",
       "      <td>489.613333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>AAAAAWEEPSSGNGTAR</td>\n",
       "      <td>2</td>\n",
       "      <td>823.382064</td>\n",
       "      <td>535.310000</td>\n",
       "      <td>367.240</td>\n",
       "      <td>822.8783</td>\n",
       "      <td>532.994286</td>\n",
       "      <td>371.006190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>AAAAPVTGPLADDPIQETITFDDFAK</td>\n",
       "      <td>3</td>\n",
       "      <td>892.112987</td>\n",
       "      <td>468.100000</td>\n",
       "      <td>997.180</td>\n",
       "      <td>891.7775</td>\n",
       "      <td>465.181500</td>\n",
       "      <td>997.738000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>AAAEDVNVTFEDQQK</td>\n",
       "      <td>2</td>\n",
       "      <td>832.891998</td>\n",
       "      <td>485.630000</td>\n",
       "      <td>471.790</td>\n",
       "      <td>832.3878</td>\n",
       "      <td>486.112727</td>\n",
       "      <td>474.475455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   file_idx                       sequence  charge  run_average_mz  \\\n",
       "0         0  AAAAAAAAAPAAAATAPTTAATTAATAAQ       2     1184.608396   \n",
       "1         0      AAAAAAAAVPSAGPAGPAPTSAAGR       2     1016.532319   \n",
       "2         0              AAAAAWEEPSSGNGTAR       2      823.382064   \n",
       "3         0     AAAAPVTGPLADDPIQETITFDDFAK       3      892.112987   \n",
       "4         0                AAAEDVNVTFEDQQK       2      832.891998   \n",
       "\n",
       "   run_average_scan  run_average_rt  theoretical_mz  experiment_average_scan  \\\n",
       "0         74.015000         601.575       1184.1049                73.528889   \n",
       "1        156.406667         486.690       1016.0286               159.998000   \n",
       "2        535.310000         367.240        822.8783               532.994286   \n",
       "3        468.100000         997.180        891.7775               465.181500   \n",
       "4        485.630000         471.790        832.3878               486.112727   \n",
       "\n",
       "   experiment_average_rt  \n",
       "0             604.371111  \n",
       "1             489.613333  \n",
       "2             371.006190  \n",
       "3             997.738000  \n",
       "4             474.475455  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the training set for file_idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = merged_df[merged_df.file_idx == 0][['theoretical_mz','experiment_average_scan','experiment_average_rt']]\n",
    "y_df = merged_df[merged_df.file_idx == 0][['run_average_mz','run_average_scan','run_average_rt']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_df.values\n",
    "y = y_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = min_max_scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val_and_test, y_train, y_val_and_test = train_test_split(X_scaled, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, X_test, y_val, y_test = train_test_split(X_val_and_test, y_val_and_test, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9697, 3) (2078, 3) (2078, 3) (9697, 3) (2078, 3) (2078, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_val.shape, X_test.shape, y_train.shape, y_val.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/darylwilding-mcbride/anaconda3/envs/py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=(3,), dtype='float32', name='main_input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Dense(256, activation='relu')(inputs)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "predictions = Dense(3, activation='sigmoid')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=inputs, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd',\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9697 samples, validate on 2078 samples\n",
      "Epoch 1/500\n",
      "9697/9697 [==============================] - 1s 114us/step - loss: 505090.8411 - acc: 0.1786 - val_loss: 504000.6159 - val_acc: 0.1800\n",
      "Epoch 2/500\n",
      "9697/9697 [==============================] - 1s 89us/step - loss: 505088.6580 - acc: 0.1768 - val_loss: 504000.6159 - val_acc: 0.1805\n",
      "Epoch 3/500\n",
      "9697/9697 [==============================] - 1s 90us/step - loss: 505088.6592 - acc: 0.1757 - val_loss: 504000.6159 - val_acc: 0.1800\n",
      "Epoch 4/500\n",
      "9697/9697 [==============================] - 1s 92us/step - loss: 505088.6558 - acc: 0.1776 - val_loss: 504000.6159 - val_acc: 0.1809\n",
      "Epoch 5/500\n",
      "9697/9697 [==============================] - 1s 93us/step - loss: 505088.6570 - acc: 0.1792 - val_loss: 504000.6159 - val_acc: 0.1843\n",
      "Epoch 6/500\n",
      "9697/9697 [==============================] - 1s 92us/step - loss: 505088.6581 - acc: 0.1806 - val_loss: 504000.6159 - val_acc: 0.1901\n",
      "Epoch 7/500\n",
      "9697/9697 [==============================] - 1s 92us/step - loss: 505088.6577 - acc: 0.1801 - val_loss: 504000.6159 - val_acc: 0.1910\n",
      "Epoch 8/500\n",
      "9697/9697 [==============================] - 1s 93us/step - loss: 505088.6574 - acc: 0.1874 - val_loss: 504000.6159 - val_acc: 0.1954\n",
      "Epoch 9/500\n",
      "9697/9697 [==============================] - 1s 94us/step - loss: 505088.6564 - acc: 0.1933 - val_loss: 504000.6159 - val_acc: 0.2074\n",
      "Epoch 10/500\n",
      "9697/9697 [==============================] - 1s 94us/step - loss: 505088.6558 - acc: 0.2016 - val_loss: 504000.6159 - val_acc: 0.2093\n",
      "Epoch 11/500\n",
      "9697/9697 [==============================] - 1s 94us/step - loss: 505088.6592 - acc: 0.2106 - val_loss: 504000.6159 - val_acc: 0.2358\n",
      "Epoch 12/500\n",
      "9697/9697 [==============================] - 1s 96us/step - loss: 505088.6567 - acc: 0.2178 - val_loss: 504000.6159 - val_acc: 0.2348\n",
      "Epoch 13/500\n",
      "9697/9697 [==============================] - 1s 98us/step - loss: 505088.6576 - acc: 0.2250 - val_loss: 504000.6159 - val_acc: 0.2416\n",
      "Epoch 14/500\n",
      "9697/9697 [==============================] - 1s 99us/step - loss: 505088.6565 - acc: 0.2351 - val_loss: 504000.6159 - val_acc: 0.2575\n",
      "Epoch 15/500\n",
      "9697/9697 [==============================] - 1s 94us/step - loss: 505088.6566 - acc: 0.2461 - val_loss: 504000.6159 - val_acc: 0.2536\n",
      "Epoch 16/500\n",
      "9697/9697 [==============================] - 1s 96us/step - loss: 505088.6577 - acc: 0.2505 - val_loss: 504000.6159 - val_acc: 0.2565\n",
      "Epoch 17/500\n",
      "9697/9697 [==============================] - 1s 95us/step - loss: 505088.6573 - acc: 0.2599 - val_loss: 504000.6159 - val_acc: 0.2777\n",
      "Epoch 18/500\n",
      "9697/9697 [==============================] - 1s 101us/step - loss: 505088.6564 - acc: 0.2620 - val_loss: 504000.6159 - val_acc: 0.2743\n",
      "Epoch 19/500\n",
      "9697/9697 [==============================] - 1s 92us/step - loss: 505088.6573 - acc: 0.2700 - val_loss: 504000.6159 - val_acc: 0.2883\n",
      "Epoch 20/500\n",
      "9697/9697 [==============================] - 1s 93us/step - loss: 505088.6593 - acc: 0.2831 - val_loss: 504000.6159 - val_acc: 0.3008\n",
      "Epoch 21/500\n",
      "9697/9697 [==============================] - 1s 94us/step - loss: 505088.6574 - acc: 0.2890 - val_loss: 504000.6159 - val_acc: 0.2988\n",
      "Epoch 22/500\n",
      "9697/9697 [==============================] - 1s 95us/step - loss: 505088.6591 - acc: 0.2903 - val_loss: 504000.6159 - val_acc: 0.2964\n",
      "Epoch 23/500\n",
      "9697/9697 [==============================] - 1s 93us/step - loss: 505088.6571 - acc: 0.2963 - val_loss: 504000.6159 - val_acc: 0.3094\n",
      "Epoch 24/500\n",
      "9697/9697 [==============================] - 1s 93us/step - loss: 505088.6563 - acc: 0.3041 - val_loss: 504000.6159 - val_acc: 0.3114\n",
      "Epoch 25/500\n",
      "9697/9697 [==============================] - 1s 93us/step - loss: 505088.6563 - acc: 0.3135 - val_loss: 504000.6159 - val_acc: 0.3263\n",
      "Epoch 26/500\n",
      "9697/9697 [==============================] - 1s 95us/step - loss: 505088.6587 - acc: 0.3229 - val_loss: 504000.6159 - val_acc: 0.3234\n",
      "Epoch 27/500\n",
      "9697/9697 [==============================] - 1s 115us/step - loss: 505088.6577 - acc: 0.3265 - val_loss: 504000.6159 - val_acc: 0.3296\n",
      "Epoch 28/500\n",
      "9697/9697 [==============================] - 1s 105us/step - loss: 505088.6561 - acc: 0.3332 - val_loss: 504000.6159 - val_acc: 0.3422\n",
      "Epoch 29/500\n",
      "9697/9697 [==============================] - 1s 93us/step - loss: 505088.6575 - acc: 0.3405 - val_loss: 504000.6159 - val_acc: 0.3484\n",
      "Epoch 30/500\n",
      "9697/9697 [==============================] - 1s 105us/step - loss: 505088.6589 - acc: 0.3404 - val_loss: 504000.6159 - val_acc: 0.3628\n",
      "Epoch 31/500\n",
      "9697/9697 [==============================] - 1s 112us/step - loss: 505088.6571 - acc: 0.3506 - val_loss: 504000.6159 - val_acc: 0.3768\n",
      "Epoch 32/500\n",
      "9697/9697 [==============================] - 1s 139us/step - loss: 505088.6590 - acc: 0.3530 - val_loss: 504000.6159 - val_acc: 0.3725\n",
      "Epoch 33/500\n",
      "9697/9697 [==============================] - 1s 108us/step - loss: 505088.6575 - acc: 0.3607 - val_loss: 504000.6159 - val_acc: 0.3730\n",
      "Epoch 34/500\n",
      "9697/9697 [==============================] - 1s 108us/step - loss: 505088.6587 - acc: 0.3696 - val_loss: 504000.6159 - val_acc: 0.3845\n",
      "Epoch 35/500\n",
      "9697/9697 [==============================] - 2s 175us/step - loss: 505088.6567 - acc: 0.3721 - val_loss: 504000.6159 - val_acc: 0.3965\n",
      "Epoch 36/500\n",
      "9697/9697 [==============================] - 1s 145us/step - loss: 505088.6558 - acc: 0.3768 - val_loss: 504000.6159 - val_acc: 0.3864\n",
      "Epoch 37/500\n",
      "9697/9697 [==============================] - 1s 117us/step - loss: 505088.6567 - acc: 0.3820 - val_loss: 504000.6159 - val_acc: 0.4004\n",
      "Epoch 38/500\n",
      "9697/9697 [==============================] - 1s 93us/step - loss: 505088.6565 - acc: 0.3883 - val_loss: 504000.6159 - val_acc: 0.3893\n",
      "Epoch 39/500\n",
      "9697/9697 [==============================] - 1s 94us/step - loss: 505088.6579 - acc: 0.3900 - val_loss: 504000.6159 - val_acc: 0.3961\n",
      "Epoch 40/500\n",
      "9697/9697 [==============================] - 1s 135us/step - loss: 505088.6586 - acc: 0.3952 - val_loss: 504000.6159 - val_acc: 0.4158\n",
      "Epoch 41/500\n",
      "9697/9697 [==============================] - 1s 124us/step - loss: 505088.6563 - acc: 0.4074 - val_loss: 504000.6159 - val_acc: 0.4196\n",
      "Epoch 42/500\n",
      "9697/9697 [==============================] - 1s 131us/step - loss: 505088.6587 - acc: 0.4111 - val_loss: 504000.6159 - val_acc: 0.4254\n",
      "Epoch 43/500\n",
      "9697/9697 [==============================] - 1s 113us/step - loss: 505088.6584 - acc: 0.4089 - val_loss: 504000.6159 - val_acc: 0.4105\n",
      "Epoch 44/500\n",
      "9697/9697 [==============================] - 1s 94us/step - loss: 505088.6582 - acc: 0.4089 - val_loss: 504000.6159 - val_acc: 0.4216\n",
      "Epoch 45/500\n",
      "9697/9697 [==============================] - 1s 98us/step - loss: 505088.6583 - acc: 0.4135 - val_loss: 504000.6159 - val_acc: 0.4206\n",
      "Epoch 46/500\n",
      "9697/9697 [==============================] - 1s 92us/step - loss: 505088.6596 - acc: 0.4123 - val_loss: 504000.6159 - val_acc: 0.4264\n",
      "Epoch 47/500\n",
      "9697/9697 [==============================] - 1s 92us/step - loss: 505088.6555 - acc: 0.4280 - val_loss: 504000.6159 - val_acc: 0.4475\n",
      "Epoch 48/500\n",
      "9697/9697 [==============================] - 1s 91us/step - loss: 505088.6573 - acc: 0.4244 - val_loss: 504000.6159 - val_acc: 0.4552\n",
      "Epoch 49/500\n",
      "9697/9697 [==============================] - 1s 93us/step - loss: 505088.6577 - acc: 0.4306 - val_loss: 504000.6159 - val_acc: 0.4384\n",
      "Epoch 50/500\n",
      "9697/9697 [==============================] - 1s 93us/step - loss: 505088.6583 - acc: 0.4309 - val_loss: 504000.6159 - val_acc: 0.4461\n",
      "Epoch 51/500\n",
      "9697/9697 [==============================] - 1s 92us/step - loss: 505088.6562 - acc: 0.4421 - val_loss: 504000.6159 - val_acc: 0.4394\n",
      "Epoch 52/500\n",
      "9697/9697 [==============================] - 1s 93us/step - loss: 505088.6573 - acc: 0.4364 - val_loss: 504000.6159 - val_acc: 0.4350\n",
      "Epoch 53/500\n",
      "9697/9697 [==============================] - 1s 92us/step - loss: 505088.6567 - acc: 0.4414 - val_loss: 504000.6159 - val_acc: 0.4706\n",
      "Epoch 54/500\n",
      "9697/9697 [==============================] - 1s 92us/step - loss: 505088.6556 - acc: 0.4421 - val_loss: 504000.6159 - val_acc: 0.4442\n",
      "Epoch 55/500\n",
      "9697/9697 [==============================] - 1s 93us/step - loss: 505088.6579 - acc: 0.4460 - val_loss: 504000.6159 - val_acc: 0.4591\n",
      "Epoch 56/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9697/9697 [==============================] - 1s 86us/step - loss: 505088.6577 - acc: 0.4492 - val_loss: 504000.6159 - val_acc: 0.4572\n",
      "Epoch 57/500\n",
      "9697/9697 [==============================] - 1s 85us/step - loss: 505088.6578 - acc: 0.4499 - val_loss: 504000.6159 - val_acc: 0.4596\n",
      "Epoch 58/500\n",
      "9697/9697 [==============================] - 1s 86us/step - loss: 505088.6573 - acc: 0.4501 - val_loss: 504000.6159 - val_acc: 0.4466\n",
      "Epoch 59/500\n",
      "9697/9697 [==============================] - 1s 88us/step - loss: 505088.6599 - acc: 0.4541 - val_loss: 504000.6159 - val_acc: 0.4673\n",
      "Epoch 60/500\n",
      "9697/9697 [==============================] - 1s 85us/step - loss: 505088.6575 - acc: 0.4583 - val_loss: 504000.6159 - val_acc: 0.4615\n",
      "Epoch 61/500\n",
      "9697/9697 [==============================] - 1s 88us/step - loss: 505088.6564 - acc: 0.4517 - val_loss: 504000.6159 - val_acc: 0.4706\n",
      "Epoch 62/500\n",
      "9697/9697 [==============================] - 1s 102us/step - loss: 505088.6570 - acc: 0.4580 - val_loss: 504000.6159 - val_acc: 0.4735\n",
      "Epoch 63/500\n",
      "9697/9697 [==============================] - 1s 130us/step - loss: 505088.6575 - acc: 0.4638 - val_loss: 504000.6159 - val_acc: 0.4668\n",
      "Epoch 64/500\n",
      "9697/9697 [==============================] - 1s 97us/step - loss: 505088.6578 - acc: 0.4648 - val_loss: 504000.6159 - val_acc: 0.4759\n",
      "Epoch 65/500\n",
      "9697/9697 [==============================] - 1s 74us/step - loss: 505088.6571 - acc: 0.4658 - val_loss: 504000.6159 - val_acc: 0.4779\n",
      "Epoch 66/500\n",
      "9697/9697 [==============================] - 1s 86us/step - loss: 505088.6567 - acc: 0.4668 - val_loss: 504000.6159 - val_acc: 0.4769\n",
      "Epoch 67/500\n",
      "9697/9697 [==============================] - 1s 77us/step - loss: 505088.6573 - acc: 0.4647 - val_loss: 504000.6159 - val_acc: 0.4755\n",
      "Epoch 68/500\n",
      "9697/9697 [==============================] - 1s 79us/step - loss: 505088.6565 - acc: 0.4719 - val_loss: 504000.6159 - val_acc: 0.4726\n",
      "Epoch 69/500\n",
      "9697/9697 [==============================] - 1s 77us/step - loss: 505088.6569 - acc: 0.4700 - val_loss: 504000.6159 - val_acc: 0.4856\n",
      "Epoch 70/500\n",
      "9697/9697 [==============================] - 1s 77us/step - loss: 505088.6572 - acc: 0.4742 - val_loss: 504000.6159 - val_acc: 0.4745\n",
      "Epoch 71/500\n",
      "9697/9697 [==============================] - 1s 76us/step - loss: 505088.6562 - acc: 0.4744 - val_loss: 504000.6159 - val_acc: 0.4808\n",
      "Epoch 72/500\n",
      "9697/9697 [==============================] - 1s 105us/step - loss: 505088.6564 - acc: 0.4817 - val_loss: 504000.6159 - val_acc: 0.4793\n",
      "Epoch 73/500\n",
      "9697/9697 [==============================] - 2s 160us/step - loss: 505088.6582 - acc: 0.4823 - val_loss: 504000.6159 - val_acc: 0.4735\n",
      "Epoch 74/500\n",
      "9697/9697 [==============================] - 1s 101us/step - loss: 505088.6571 - acc: 0.4821 - val_loss: 504000.6159 - val_acc: 0.4875\n",
      "Epoch 75/500\n",
      "9697/9697 [==============================] - 1s 83us/step - loss: 505088.6560 - acc: 0.4805 - val_loss: 504000.6159 - val_acc: 0.4885\n",
      "Epoch 76/500\n",
      "9697/9697 [==============================] - 1s 87us/step - loss: 505088.6561 - acc: 0.4848 - val_loss: 504000.6159 - val_acc: 0.4885\n",
      "Epoch 77/500\n",
      "9697/9697 [==============================] - 1s 76us/step - loss: 505088.6578 - acc: 0.4827 - val_loss: 504000.6159 - val_acc: 0.4851\n",
      "Epoch 78/500\n",
      "9697/9697 [==============================] - 1s 93us/step - loss: 505088.6558 - acc: 0.4825 - val_loss: 504000.6159 - val_acc: 0.4836\n",
      "Epoch 79/500\n",
      "9697/9697 [==============================] - 1s 90us/step - loss: 505088.6576 - acc: 0.4828 - val_loss: 504000.6159 - val_acc: 0.4865\n",
      "Epoch 80/500\n",
      "9697/9697 [==============================] - 1s 97us/step - loss: 505088.6583 - acc: 0.4879 - val_loss: 504000.6159 - val_acc: 0.4860\n",
      "Epoch 81/500\n",
      "9697/9697 [==============================] - 1s 86us/step - loss: 505088.6587 - acc: 0.4846 - val_loss: 504000.6159 - val_acc: 0.4913\n",
      "Epoch 82/500\n",
      "9697/9697 [==============================] - 1s 120us/step - loss: 505088.6584 - acc: 0.4921 - val_loss: 504000.6159 - val_acc: 0.4957\n",
      "Epoch 83/500\n",
      "9697/9697 [==============================] - 1s 86us/step - loss: 505088.6556 - acc: 0.4931 - val_loss: 504000.6159 - val_acc: 0.4962\n",
      "Epoch 84/500\n",
      "9697/9697 [==============================] - 1s 80us/step - loss: 505088.6578 - acc: 0.4890 - val_loss: 504000.6159 - val_acc: 0.4986\n",
      "Epoch 85/500\n",
      "9697/9697 [==============================] - 1s 83us/step - loss: 505088.6566 - acc: 0.4919 - val_loss: 504000.6159 - val_acc: 0.4913\n",
      "Epoch 86/500\n",
      "9697/9697 [==============================] - 1s 92us/step - loss: 505088.6558 - acc: 0.4943 - val_loss: 504000.6159 - val_acc: 0.4981\n",
      "Epoch 87/500\n",
      "9697/9697 [==============================] - 1s 76us/step - loss: 505088.6562 - acc: 0.4933 - val_loss: 504000.6159 - val_acc: 0.5005\n",
      "Epoch 88/500\n",
      "9697/9697 [==============================] - 1s 88us/step - loss: 505088.6586 - acc: 0.4979 - val_loss: 504000.6159 - val_acc: 0.5019\n",
      "Epoch 89/500\n",
      "9697/9697 [==============================] - 1s 96us/step - loss: 505088.6580 - acc: 0.4964 - val_loss: 504000.6159 - val_acc: 0.4928\n",
      "Epoch 90/500\n",
      "9697/9697 [==============================] - 1s 90us/step - loss: 505088.6574 - acc: 0.4940 - val_loss: 504000.6159 - val_acc: 0.5072\n",
      "Epoch 91/500\n",
      "9697/9697 [==============================] - 1s 145us/step - loss: 505088.6566 - acc: 0.4976 - val_loss: 504000.6159 - val_acc: 0.5014\n",
      "Epoch 92/500\n",
      "9697/9697 [==============================] - 1s 150us/step - loss: 505088.6574 - acc: 0.4978 - val_loss: 504000.6159 - val_acc: 0.5034\n",
      "Epoch 93/500\n",
      "9697/9697 [==============================] - 1s 143us/step - loss: 505088.6565 - acc: 0.4995 - val_loss: 504000.6159 - val_acc: 0.5010\n",
      "Epoch 94/500\n",
      "9697/9697 [==============================] - 1s 154us/step - loss: 505088.6569 - acc: 0.4994 - val_loss: 504000.6159 - val_acc: 0.5082\n",
      "Epoch 95/500\n",
      "9697/9697 [==============================] - 1s 97us/step - loss: 505088.6584 - acc: 0.4986 - val_loss: 504000.6159 - val_acc: 0.5125\n",
      "Epoch 96/500\n",
      "9697/9697 [==============================] - 1s 88us/step - loss: 505088.6567 - acc: 0.5038 - val_loss: 504000.6159 - val_acc: 0.5120\n",
      "Epoch 97/500\n",
      "9697/9697 [==============================] - 1s 92us/step - loss: 505088.6572 - acc: 0.4995 - val_loss: 504000.6159 - val_acc: 0.5034\n",
      "Epoch 98/500\n",
      "9697/9697 [==============================] - 1s 83us/step - loss: 505088.6564 - acc: 0.5047 - val_loss: 504000.6159 - val_acc: 0.5058\n",
      "Epoch 99/500\n",
      "9697/9697 [==============================] - 1s 75us/step - loss: 505088.6578 - acc: 0.4986 - val_loss: 504000.6159 - val_acc: 0.5087\n",
      "Epoch 100/500\n",
      "9697/9697 [==============================] - 1s 76us/step - loss: 505088.6575 - acc: 0.5026 - val_loss: 504000.6159 - val_acc: 0.5154\n",
      "Epoch 101/500\n",
      "9697/9697 [==============================] - 1s 89us/step - loss: 505088.6592 - acc: 0.5060 - val_loss: 504000.6159 - val_acc: 0.5149\n",
      "Epoch 102/500\n",
      "9697/9697 [==============================] - 1s 82us/step - loss: 505088.6569 - acc: 0.5065 - val_loss: 504000.6159 - val_acc: 0.5159\n",
      "Epoch 103/500\n",
      "9697/9697 [==============================] - 1s 98us/step - loss: 505088.6576 - acc: 0.5028 - val_loss: 504000.6159 - val_acc: 0.5168\n",
      "Epoch 104/500\n",
      "9697/9697 [==============================] - 1s 147us/step - loss: 505088.6586 - acc: 0.5090 - val_loss: 504000.6159 - val_acc: 0.5077\n",
      "Epoch 105/500\n",
      "9697/9697 [==============================] - 1s 155us/step - loss: 505088.6558 - acc: 0.5095 - val_loss: 504000.6159 - val_acc: 0.5082\n",
      "Epoch 106/500\n",
      "9697/9697 [==============================] - 1s 82us/step - loss: 505088.6559 - acc: 0.5093 - val_loss: 504000.6159 - val_acc: 0.5125\n",
      "Epoch 107/500\n",
      "9697/9697 [==============================] - 2s 158us/step - loss: 505088.6579 - acc: 0.5091 - val_loss: 504000.6159 - val_acc: 0.5173\n",
      "Epoch 108/500\n",
      "9697/9697 [==============================] - 1s 129us/step - loss: 505088.6590 - acc: 0.5112 - val_loss: 504000.6159 - val_acc: 0.5072\n",
      "Epoch 109/500\n",
      "9697/9697 [==============================] - 1s 80us/step - loss: 505088.6579 - acc: 0.5101 - val_loss: 504000.6159 - val_acc: 0.5106\n",
      "Epoch 110/500\n",
      "9697/9697 [==============================] - 1s 74us/step - loss: 505088.6573 - acc: 0.5113 - val_loss: 504000.6159 - val_acc: 0.5231\n",
      "Epoch 111/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9697/9697 [==============================] - 1s 78us/step - loss: 505088.6583 - acc: 0.5118 - val_loss: 504000.6159 - val_acc: 0.5217\n",
      "Epoch 112/500\n",
      "9697/9697 [==============================] - 1s 78us/step - loss: 505088.6573 - acc: 0.5135 - val_loss: 504000.6159 - val_acc: 0.5125\n",
      "Epoch 113/500\n",
      "9697/9697 [==============================] - 1s 86us/step - loss: 505088.6582 - acc: 0.5124 - val_loss: 504000.6159 - val_acc: 0.5245\n",
      "Epoch 114/500\n",
      "9697/9697 [==============================] - 1s 104us/step - loss: 505088.6596 - acc: 0.5171 - val_loss: 504000.6159 - val_acc: 0.5173\n",
      "Epoch 115/500\n",
      "9697/9697 [==============================] - 1s 78us/step - loss: 505088.6572 - acc: 0.5149 - val_loss: 504000.6159 - val_acc: 0.5245\n",
      "Epoch 116/500\n",
      "9697/9697 [==============================] - 1s 77us/step - loss: 505088.6575 - acc: 0.5151 - val_loss: 504000.6159 - val_acc: 0.5149\n",
      "Epoch 117/500\n",
      "9697/9697 [==============================] - 1s 81us/step - loss: 505088.6575 - acc: 0.5124 - val_loss: 504000.6159 - val_acc: 0.5212\n",
      "Epoch 118/500\n",
      "9697/9697 [==============================] - 1s 75us/step - loss: 505088.6567 - acc: 0.5187 - val_loss: 504000.6159 - val_acc: 0.5183\n",
      "Epoch 119/500\n",
      "9697/9697 [==============================] - 1s 81us/step - loss: 505088.6570 - acc: 0.5152 - val_loss: 504000.6159 - val_acc: 0.5192\n",
      "Epoch 120/500\n",
      "9697/9697 [==============================] - 1s 109us/step - loss: 505088.6576 - acc: 0.5162 - val_loss: 504000.6159 - val_acc: 0.5279\n",
      "Epoch 121/500\n",
      "9697/9697 [==============================] - 1s 82us/step - loss: 505088.6582 - acc: 0.5153 - val_loss: 504000.6159 - val_acc: 0.5231\n",
      "Epoch 122/500\n",
      "9697/9697 [==============================] - 1s 76us/step - loss: 505088.6574 - acc: 0.5176 - val_loss: 504000.6159 - val_acc: 0.5284\n",
      "Epoch 123/500\n",
      "9697/9697 [==============================] - 1s 76us/step - loss: 505088.6574 - acc: 0.5205 - val_loss: 504000.6159 - val_acc: 0.5231\n",
      "Epoch 124/500\n",
      "9697/9697 [==============================] - 1s 77us/step - loss: 505088.6560 - acc: 0.5209 - val_loss: 504000.6159 - val_acc: 0.5221\n",
      "Epoch 125/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6570 - acc: 0.5210 - val_loss: 504000.6159 - val_acc: 0.5269\n",
      "Epoch 126/500\n",
      "9697/9697 [==============================] - 1s 96us/step - loss: 505088.6574 - acc: 0.5209 - val_loss: 504000.6159 - val_acc: 0.5245\n",
      "Epoch 127/500\n",
      "9697/9697 [==============================] - 1s 93us/step - loss: 505088.6556 - acc: 0.5222 - val_loss: 504000.6159 - val_acc: 0.5351\n",
      "Epoch 128/500\n",
      "9697/9697 [==============================] - 1s 76us/step - loss: 505088.6566 - acc: 0.5201 - val_loss: 504000.6159 - val_acc: 0.5255\n",
      "Epoch 129/500\n",
      "9697/9697 [==============================] - 1s 74us/step - loss: 505088.6565 - acc: 0.5212 - val_loss: 504000.6159 - val_acc: 0.5226\n",
      "Epoch 130/500\n",
      "9697/9697 [==============================] - 1s 75us/step - loss: 505088.6561 - acc: 0.5242 - val_loss: 504000.6159 - val_acc: 0.5284\n",
      "Epoch 131/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6566 - acc: 0.5227 - val_loss: 504000.6159 - val_acc: 0.5279\n",
      "Epoch 132/500\n",
      "9697/9697 [==============================] - 1s 78us/step - loss: 505088.6562 - acc: 0.5252 - val_loss: 504000.6159 - val_acc: 0.5279\n",
      "Epoch 133/500\n",
      "9697/9697 [==============================] - 1s 94us/step - loss: 505088.6576 - acc: 0.5250 - val_loss: 504000.6159 - val_acc: 0.5265\n",
      "Epoch 134/500\n",
      "9697/9697 [==============================] - 1s 75us/step - loss: 505088.6589 - acc: 0.5239 - val_loss: 504000.6159 - val_acc: 0.5327\n",
      "Epoch 135/500\n",
      "9697/9697 [==============================] - 1s 79us/step - loss: 505088.6591 - acc: 0.5261 - val_loss: 504000.6159 - val_acc: 0.5279\n",
      "Epoch 136/500\n",
      "9697/9697 [==============================] - 1s 85us/step - loss: 505088.6579 - acc: 0.5213 - val_loss: 504000.6159 - val_acc: 0.5332\n",
      "Epoch 137/500\n",
      "9697/9697 [==============================] - 1s 78us/step - loss: 505088.6552 - acc: 0.5245 - val_loss: 504000.6159 - val_acc: 0.5308\n",
      "Epoch 138/500\n",
      "9697/9697 [==============================] - 1s 74us/step - loss: 505088.6578 - acc: 0.5268 - val_loss: 504000.6159 - val_acc: 0.5269\n",
      "Epoch 139/500\n",
      "9697/9697 [==============================] - 1s 94us/step - loss: 505088.6557 - acc: 0.5265 - val_loss: 504000.6159 - val_acc: 0.5298\n",
      "Epoch 140/500\n",
      "9697/9697 [==============================] - 1s 78us/step - loss: 505088.6560 - acc: 0.5275 - val_loss: 504000.6159 - val_acc: 0.5361\n",
      "Epoch 141/500\n",
      "9697/9697 [==============================] - 1s 89us/step - loss: 505088.6571 - acc: 0.5232 - val_loss: 504000.6159 - val_acc: 0.5337\n",
      "Epoch 142/500\n",
      "9697/9697 [==============================] - 1s 85us/step - loss: 505088.6591 - acc: 0.5275 - val_loss: 504000.6159 - val_acc: 0.5380\n",
      "Epoch 143/500\n",
      "9697/9697 [==============================] - 1s 75us/step - loss: 505088.6568 - acc: 0.5268 - val_loss: 504000.6159 - val_acc: 0.5346\n",
      "Epoch 144/500\n",
      "9697/9697 [==============================] - 1s 72us/step - loss: 505088.6579 - acc: 0.5279 - val_loss: 504000.6159 - val_acc: 0.5308\n",
      "Epoch 145/500\n",
      "9697/9697 [==============================] - 1s 88us/step - loss: 505088.6576 - acc: 0.5284 - val_loss: 504000.6159 - val_acc: 0.5322\n",
      "Epoch 146/500\n",
      "9697/9697 [==============================] - 1s 100us/step - loss: 505088.6561 - acc: 0.5304 - val_loss: 504000.6159 - val_acc: 0.5318\n",
      "Epoch 147/500\n",
      "9697/9697 [==============================] - 1s 101us/step - loss: 505088.6551 - acc: 0.5309 - val_loss: 504000.6159 - val_acc: 0.5351\n",
      "Epoch 148/500\n",
      "9697/9697 [==============================] - 1s 99us/step - loss: 505088.6579 - acc: 0.5329 - val_loss: 504000.6159 - val_acc: 0.5313\n",
      "Epoch 149/500\n",
      "9697/9697 [==============================] - 1s 93us/step - loss: 505088.6573 - acc: 0.5283 - val_loss: 504000.6159 - val_acc: 0.5356\n",
      "Epoch 150/500\n",
      "9697/9697 [==============================] - 1s 81us/step - loss: 505088.6595 - acc: 0.5283 - val_loss: 504000.6159 - val_acc: 0.5390\n",
      "Epoch 151/500\n",
      "9697/9697 [==============================] - 1s 102us/step - loss: 505088.6583 - acc: 0.5317 - val_loss: 504000.6159 - val_acc: 0.5356\n",
      "Epoch 152/500\n",
      "9697/9697 [==============================] - 1s 113us/step - loss: 505088.6595 - acc: 0.5346 - val_loss: 504000.6159 - val_acc: 0.5346\n",
      "Epoch 153/500\n",
      "9697/9697 [==============================] - 1s 80us/step - loss: 505088.6581 - acc: 0.5294 - val_loss: 504000.6159 - val_acc: 0.5390\n",
      "Epoch 154/500\n",
      "9697/9697 [==============================] - 1s 105us/step - loss: 505088.6568 - acc: 0.5306 - val_loss: 504000.6159 - val_acc: 0.5371\n",
      "Epoch 155/500\n",
      "9697/9697 [==============================] - 1s 99us/step - loss: 505088.6573 - acc: 0.5346 - val_loss: 504000.6159 - val_acc: 0.5342\n",
      "Epoch 156/500\n",
      "9697/9697 [==============================] - 1s 91us/step - loss: 505088.6579 - acc: 0.5302 - val_loss: 504000.6159 - val_acc: 0.5361\n",
      "Epoch 157/500\n",
      "9697/9697 [==============================] - 1s 86us/step - loss: 505088.6567 - acc: 0.5289 - val_loss: 504000.6159 - val_acc: 0.5390\n",
      "Epoch 158/500\n",
      "9697/9697 [==============================] - 1s 113us/step - loss: 505088.6575 - acc: 0.5318 - val_loss: 504000.6159 - val_acc: 0.5332\n",
      "Epoch 159/500\n",
      "9697/9697 [==============================] - 1s 112us/step - loss: 505088.6560 - acc: 0.5311 - val_loss: 504000.6159 - val_acc: 0.5385\n",
      "Epoch 160/500\n",
      "9697/9697 [==============================] - 1s 117us/step - loss: 505088.6579 - acc: 0.5338 - val_loss: 504000.6159 - val_acc: 0.5356\n",
      "Epoch 161/500\n",
      "9697/9697 [==============================] - 1s 113us/step - loss: 505088.6567 - acc: 0.5344 - val_loss: 504000.6159 - val_acc: 0.5462\n",
      "Epoch 162/500\n",
      "9697/9697 [==============================] - 1s 77us/step - loss: 505088.6567 - acc: 0.5344 - val_loss: 504000.6159 - val_acc: 0.5414\n",
      "Epoch 163/500\n",
      "9697/9697 [==============================] - 1s 74us/step - loss: 505088.6575 - acc: 0.5351 - val_loss: 504000.6159 - val_acc: 0.5414\n",
      "Epoch 164/500\n",
      "9697/9697 [==============================] - 1s 74us/step - loss: 505088.6568 - acc: 0.5381 - val_loss: 504000.6159 - val_acc: 0.5452\n",
      "Epoch 165/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6587 - acc: 0.5361 - val_loss: 504000.6159 - val_acc: 0.5375\n",
      "Epoch 166/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6592 - acc: 0.5349 - val_loss: 504000.6159 - val_acc: 0.5443\n",
      "Epoch 167/500\n",
      "9697/9697 [==============================] - 1s 74us/step - loss: 505088.6574 - acc: 0.5359 - val_loss: 504000.6159 - val_acc: 0.5346\n",
      "Epoch 168/500\n",
      "9697/9697 [==============================] - 1s 74us/step - loss: 505088.6577 - acc: 0.5353 - val_loss: 504000.6159 - val_acc: 0.5423\n",
      "Epoch 169/500\n",
      "9697/9697 [==============================] - 1s 74us/step - loss: 505088.6571 - acc: 0.5375 - val_loss: 504000.6159 - val_acc: 0.5385\n",
      "Epoch 170/500\n",
      "9697/9697 [==============================] - 1s 75us/step - loss: 505088.6575 - acc: 0.5373 - val_loss: 504000.6159 - val_acc: 0.5443\n",
      "Epoch 171/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6573 - acc: 0.5365 - val_loss: 504000.6159 - val_acc: 0.5486\n",
      "Epoch 172/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6554 - acc: 0.5364 - val_loss: 504000.6159 - val_acc: 0.5438\n",
      "Epoch 173/500\n",
      "9697/9697 [==============================] - 1s 76us/step - loss: 505088.6561 - acc: 0.5389 - val_loss: 504000.6159 - val_acc: 0.5428\n",
      "Epoch 174/500\n",
      "9697/9697 [==============================] - 1s 96us/step - loss: 505088.6581 - acc: 0.5368 - val_loss: 504000.6159 - val_acc: 0.5443\n",
      "Epoch 175/500\n",
      "9697/9697 [==============================] - 1s 95us/step - loss: 505088.6557 - acc: 0.5349 - val_loss: 504000.6159 - val_acc: 0.5366\n",
      "Epoch 176/500\n",
      "9697/9697 [==============================] - 1s 107us/step - loss: 505088.6562 - acc: 0.5409 - val_loss: 504000.6159 - val_acc: 0.5452\n",
      "Epoch 177/500\n",
      "9697/9697 [==============================] - 1s 76us/step - loss: 505088.6581 - acc: 0.5389 - val_loss: 504000.6159 - val_acc: 0.5443\n",
      "Epoch 178/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6563 - acc: 0.5401 - val_loss: 504000.6159 - val_acc: 0.5448\n",
      "Epoch 179/500\n",
      "9697/9697 [==============================] - 1s 74us/step - loss: 505088.6587 - acc: 0.5380 - val_loss: 504000.6159 - val_acc: 0.5457\n",
      "Epoch 180/500\n",
      "9697/9697 [==============================] - 1s 74us/step - loss: 505088.6575 - acc: 0.5376 - val_loss: 504000.6159 - val_acc: 0.5491\n",
      "Epoch 181/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6571 - acc: 0.5392 - val_loss: 504000.6159 - val_acc: 0.5476\n",
      "Epoch 182/500\n",
      "9697/9697 [==============================] - 1s 74us/step - loss: 505088.6567 - acc: 0.5385 - val_loss: 504000.6159 - val_acc: 0.5438\n",
      "Epoch 183/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6566 - acc: 0.5411 - val_loss: 504000.6159 - val_acc: 0.5457\n",
      "Epoch 184/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6560 - acc: 0.5401 - val_loss: 504000.6159 - val_acc: 0.5428\n",
      "Epoch 185/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6567 - acc: 0.5405 - val_loss: 504000.6159 - val_acc: 0.5472\n",
      "Epoch 186/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6579 - acc: 0.5376 - val_loss: 504000.6159 - val_acc: 0.5486\n",
      "Epoch 187/500\n",
      "9697/9697 [==============================] - 1s 74us/step - loss: 505088.6595 - acc: 0.5423 - val_loss: 504000.6159 - val_acc: 0.5409\n",
      "Epoch 188/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6583 - acc: 0.5401 - val_loss: 504000.6159 - val_acc: 0.5452\n",
      "Epoch 189/500\n",
      "9697/9697 [==============================] - 1s 72us/step - loss: 505088.6570 - acc: 0.5401 - val_loss: 504000.6159 - val_acc: 0.5452\n",
      "Epoch 190/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6580 - acc: 0.5410 - val_loss: 504000.6159 - val_acc: 0.5423\n",
      "Epoch 191/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6558 - acc: 0.5394 - val_loss: 504000.6159 - val_acc: 0.5491\n",
      "Epoch 192/500\n",
      "9697/9697 [==============================] - 1s 72us/step - loss: 505088.6568 - acc: 0.5423 - val_loss: 504000.6159 - val_acc: 0.5428\n",
      "Epoch 193/500\n",
      "9697/9697 [==============================] - 1s 72us/step - loss: 505088.6603 - acc: 0.5425 - val_loss: 504000.6159 - val_acc: 0.5438\n",
      "Epoch 194/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6582 - acc: 0.5440 - val_loss: 504000.6159 - val_acc: 0.5481\n",
      "Epoch 195/500\n",
      "9697/9697 [==============================] - 1s 72us/step - loss: 505088.6571 - acc: 0.5414 - val_loss: 504000.6159 - val_acc: 0.5510\n",
      "Epoch 196/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6585 - acc: 0.5420 - val_loss: 504000.6159 - val_acc: 0.5428\n",
      "Epoch 197/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6570 - acc: 0.5431 - val_loss: 504000.6159 - val_acc: 0.5481\n",
      "Epoch 198/500\n",
      "9697/9697 [==============================] - 1s 72us/step - loss: 505088.6578 - acc: 0.5417 - val_loss: 504000.6159 - val_acc: 0.5462\n",
      "Epoch 199/500\n",
      "9697/9697 [==============================] - 1s 75us/step - loss: 505088.6569 - acc: 0.5434 - val_loss: 504000.6159 - val_acc: 0.5500\n",
      "Epoch 200/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6583 - acc: 0.5438 - val_loss: 504000.6159 - val_acc: 0.5539\n",
      "Epoch 201/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6576 - acc: 0.5436 - val_loss: 504000.6159 - val_acc: 0.5500\n",
      "Epoch 202/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6571 - acc: 0.5451 - val_loss: 504000.6159 - val_acc: 0.5500\n",
      "Epoch 203/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6555 - acc: 0.5438 - val_loss: 504000.6159 - val_acc: 0.5500\n",
      "Epoch 204/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6563 - acc: 0.5425 - val_loss: 504000.6159 - val_acc: 0.5462\n",
      "Epoch 205/500\n",
      "9697/9697 [==============================] - 1s 75us/step - loss: 505088.6577 - acc: 0.5449 - val_loss: 504000.6159 - val_acc: 0.5467\n",
      "Epoch 206/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6567 - acc: 0.5449 - val_loss: 504000.6159 - val_acc: 0.5491\n",
      "Epoch 207/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6560 - acc: 0.5438 - val_loss: 504000.6159 - val_acc: 0.5515\n",
      "Epoch 208/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6586 - acc: 0.5439 - val_loss: 504000.6159 - val_acc: 0.5481\n",
      "Epoch 209/500\n",
      "9697/9697 [==============================] - 1s 72us/step - loss: 505088.6546 - acc: 0.5432 - val_loss: 504000.6159 - val_acc: 0.5457\n",
      "Epoch 210/500\n",
      "9697/9697 [==============================] - 1s 74us/step - loss: 505088.6568 - acc: 0.5450 - val_loss: 504000.6159 - val_acc: 0.5476\n",
      "Epoch 211/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6569 - acc: 0.5456 - val_loss: 504000.6159 - val_acc: 0.5510\n",
      "Epoch 212/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6566 - acc: 0.5464 - val_loss: 504000.6159 - val_acc: 0.5534\n",
      "Epoch 213/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6557 - acc: 0.5444 - val_loss: 504000.6159 - val_acc: 0.5467\n",
      "Epoch 214/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6571 - acc: 0.5454 - val_loss: 504000.6159 - val_acc: 0.5520\n",
      "Epoch 215/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6600 - acc: 0.5463 - val_loss: 504000.6159 - val_acc: 0.5462\n",
      "Epoch 216/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6579 - acc: 0.5461 - val_loss: 504000.6159 - val_acc: 0.5529\n",
      "Epoch 217/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6578 - acc: 0.5473 - val_loss: 504000.6159 - val_acc: 0.5491\n",
      "Epoch 218/500\n",
      "9697/9697 [==============================] - 1s 75us/step - loss: 505088.6572 - acc: 0.5460 - val_loss: 504000.6159 - val_acc: 0.5520\n",
      "Epoch 219/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6580 - acc: 0.5458 - val_loss: 504000.6159 - val_acc: 0.5491\n",
      "Epoch 220/500\n",
      "9697/9697 [==============================] - 1s 74us/step - loss: 505088.6586 - acc: 0.5480 - val_loss: 504000.6159 - val_acc: 0.5472\n",
      "Epoch 221/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9697/9697 [==============================] - 1s 72us/step - loss: 505088.6568 - acc: 0.5469 - val_loss: 504000.6159 - val_acc: 0.5491\n",
      "Epoch 222/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6587 - acc: 0.5459 - val_loss: 504000.6159 - val_acc: 0.5496\n",
      "Epoch 223/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6570 - acc: 0.5461 - val_loss: 504000.6159 - val_acc: 0.5476\n",
      "Epoch 224/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6604 - acc: 0.5471 - val_loss: 504000.6159 - val_acc: 0.5510\n",
      "Epoch 225/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6585 - acc: 0.5482 - val_loss: 504000.6159 - val_acc: 0.5529\n",
      "Epoch 226/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6567 - acc: 0.5460 - val_loss: 504000.6159 - val_acc: 0.5510\n",
      "Epoch 227/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6555 - acc: 0.5474 - val_loss: 504000.6159 - val_acc: 0.5510\n",
      "Epoch 228/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6569 - acc: 0.5486 - val_loss: 504000.6159 - val_acc: 0.5472\n",
      "Epoch 229/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6591 - acc: 0.5486 - val_loss: 504000.6159 - val_acc: 0.5525\n",
      "Epoch 230/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6576 - acc: 0.5479 - val_loss: 504000.6159 - val_acc: 0.5486\n",
      "Epoch 231/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6555 - acc: 0.5493 - val_loss: 504000.6159 - val_acc: 0.5481\n",
      "Epoch 232/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6566 - acc: 0.5494 - val_loss: 504000.6159 - val_acc: 0.5558\n",
      "Epoch 233/500\n",
      "9697/9697 [==============================] - 1s 75us/step - loss: 505088.6564 - acc: 0.5477 - val_loss: 504000.6159 - val_acc: 0.5534\n",
      "Epoch 234/500\n",
      "9697/9697 [==============================] - 1s 74us/step - loss: 505088.6560 - acc: 0.5488 - val_loss: 504000.6159 - val_acc: 0.5558\n",
      "Epoch 235/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6574 - acc: 0.5482 - val_loss: 504000.6159 - val_acc: 0.5549\n",
      "Epoch 236/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6562 - acc: 0.5480 - val_loss: 504000.6159 - val_acc: 0.5525\n",
      "Epoch 237/500\n",
      "9697/9697 [==============================] - 1s 74us/step - loss: 505088.6590 - acc: 0.5496 - val_loss: 504000.6159 - val_acc: 0.5529\n",
      "Epoch 238/500\n",
      "9697/9697 [==============================] - 1s 94us/step - loss: 505088.6586 - acc: 0.5496 - val_loss: 504000.6159 - val_acc: 0.5529\n",
      "Epoch 239/500\n",
      "9697/9697 [==============================] - 1s 80us/step - loss: 505088.6576 - acc: 0.5498 - val_loss: 504000.6159 - val_acc: 0.5525\n",
      "Epoch 240/500\n",
      "9697/9697 [==============================] - 1s 81us/step - loss: 505088.6562 - acc: 0.5498 - val_loss: 504000.6159 - val_acc: 0.5472\n",
      "Epoch 241/500\n",
      "9697/9697 [==============================] - 1s 124us/step - loss: 505088.6571 - acc: 0.5476 - val_loss: 504000.6159 - val_acc: 0.5539\n",
      "Epoch 242/500\n",
      "9697/9697 [==============================] - 1s 93us/step - loss: 505088.6567 - acc: 0.5491 - val_loss: 504000.6159 - val_acc: 0.5505\n",
      "Epoch 243/500\n",
      "9697/9697 [==============================] - 1s 89us/step - loss: 505088.6577 - acc: 0.5482 - val_loss: 504000.6159 - val_acc: 0.5549\n",
      "Epoch 244/500\n",
      "9697/9697 [==============================] - 1s 88us/step - loss: 505088.6563 - acc: 0.5474 - val_loss: 504000.6159 - val_acc: 0.5563\n",
      "Epoch 245/500\n",
      "9697/9697 [==============================] - 1s 76us/step - loss: 505088.6569 - acc: 0.5510 - val_loss: 504000.6159 - val_acc: 0.5539\n",
      "Epoch 246/500\n",
      "9697/9697 [==============================] - 1s 93us/step - loss: 505088.6556 - acc: 0.5502 - val_loss: 504000.6159 - val_acc: 0.5534\n",
      "Epoch 247/500\n",
      "9697/9697 [==============================] - 1s 103us/step - loss: 505088.6585 - acc: 0.5509 - val_loss: 504000.6159 - val_acc: 0.5534\n",
      "Epoch 248/500\n",
      "9697/9697 [==============================] - 1s 77us/step - loss: 505088.6565 - acc: 0.5509 - val_loss: 504000.6159 - val_acc: 0.5544\n",
      "Epoch 249/500\n",
      "9697/9697 [==============================] - 1s 92us/step - loss: 505088.6585 - acc: 0.5508 - val_loss: 504000.6159 - val_acc: 0.5525\n",
      "Epoch 250/500\n",
      "9697/9697 [==============================] - 1s 82us/step - loss: 505088.6566 - acc: 0.5496 - val_loss: 504000.6159 - val_acc: 0.5553\n",
      "Epoch 251/500\n",
      "9697/9697 [==============================] - 1s 101us/step - loss: 505088.6561 - acc: 0.5498 - val_loss: 504000.6159 - val_acc: 0.5520\n",
      "Epoch 252/500\n",
      "9697/9697 [==============================] - 1s 76us/step - loss: 505088.6598 - acc: 0.5512 - val_loss: 504000.6159 - val_acc: 0.5597\n",
      "Epoch 253/500\n",
      "9697/9697 [==============================] - 1s 91us/step - loss: 505088.6556 - acc: 0.5509 - val_loss: 504000.6159 - val_acc: 0.5539\n",
      "Epoch 254/500\n",
      "9697/9697 [==============================] - 1s 86us/step - loss: 505088.6558 - acc: 0.5521 - val_loss: 504000.6159 - val_acc: 0.5510\n",
      "Epoch 255/500\n",
      "9697/9697 [==============================] - 1s 89us/step - loss: 505088.6564 - acc: 0.5511 - val_loss: 504000.6159 - val_acc: 0.5549\n",
      "Epoch 256/500\n",
      "9697/9697 [==============================] - 1s 86us/step - loss: 505088.6588 - acc: 0.5502 - val_loss: 504000.6159 - val_acc: 0.5558\n",
      "Epoch 257/500\n",
      "9697/9697 [==============================] - 1s 94us/step - loss: 505088.6575 - acc: 0.5518 - val_loss: 504000.6159 - val_acc: 0.5544\n",
      "Epoch 258/500\n",
      "9697/9697 [==============================] - 1s 81us/step - loss: 505088.6595 - acc: 0.5513 - val_loss: 504000.6159 - val_acc: 0.5525\n",
      "Epoch 259/500\n",
      "9697/9697 [==============================] - 1s 75us/step - loss: 505088.6570 - acc: 0.5504 - val_loss: 504000.6159 - val_acc: 0.5525\n",
      "Epoch 260/500\n",
      "9697/9697 [==============================] - 1s 74us/step - loss: 505088.6559 - acc: 0.5510 - val_loss: 504000.6159 - val_acc: 0.5534\n",
      "Epoch 261/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6588 - acc: 0.5510 - val_loss: 504000.6159 - val_acc: 0.5539\n",
      "Epoch 262/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6580 - acc: 0.5519 - val_loss: 504000.6159 - val_acc: 0.5558\n",
      "Epoch 263/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6561 - acc: 0.5517 - val_loss: 504000.6159 - val_acc: 0.5525\n",
      "Epoch 264/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6577 - acc: 0.5512 - val_loss: 504000.6159 - val_acc: 0.5539\n",
      "Epoch 265/500\n",
      "9697/9697 [==============================] - 1s 74us/step - loss: 505088.6564 - acc: 0.5516 - val_loss: 504000.6159 - val_acc: 0.5534\n",
      "Epoch 266/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6576 - acc: 0.5521 - val_loss: 504000.6159 - val_acc: 0.5544\n",
      "Epoch 267/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6581 - acc: 0.5535 - val_loss: 504000.6159 - val_acc: 0.5577\n",
      "Epoch 268/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6580 - acc: 0.5520 - val_loss: 504000.6159 - val_acc: 0.5568\n",
      "Epoch 269/500\n",
      "9697/9697 [==============================] - 1s 72us/step - loss: 505088.6568 - acc: 0.5529 - val_loss: 504000.6159 - val_acc: 0.5534\n",
      "Epoch 270/500\n",
      "9697/9697 [==============================] - 1s 74us/step - loss: 505088.6585 - acc: 0.5546 - val_loss: 504000.6159 - val_acc: 0.5582\n",
      "Epoch 271/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6565 - acc: 0.5532 - val_loss: 504000.6159 - val_acc: 0.5558\n",
      "Epoch 272/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6594 - acc: 0.5511 - val_loss: 504000.6159 - val_acc: 0.5544\n",
      "Epoch 273/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6569 - acc: 0.5516 - val_loss: 504000.6159 - val_acc: 0.5568\n",
      "Epoch 274/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6554 - acc: 0.5519 - val_loss: 504000.6159 - val_acc: 0.5544\n",
      "Epoch 275/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6580 - acc: 0.5533 - val_loss: 504000.6159 - val_acc: 0.5544\n",
      "Epoch 276/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6577 - acc: 0.5530 - val_loss: 504000.6159 - val_acc: 0.5582\n",
      "Epoch 277/500\n",
      "9697/9697 [==============================] - 1s 72us/step - loss: 505088.6566 - acc: 0.5519 - val_loss: 504000.6159 - val_acc: 0.5544\n",
      "Epoch 278/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6563 - acc: 0.5545 - val_loss: 504000.6159 - val_acc: 0.5549\n",
      "Epoch 279/500\n",
      "9697/9697 [==============================] - 1s 74us/step - loss: 505088.6571 - acc: 0.5536 - val_loss: 504000.6159 - val_acc: 0.5553\n",
      "Epoch 280/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6575 - acc: 0.5522 - val_loss: 504000.6159 - val_acc: 0.5549\n",
      "Epoch 281/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6587 - acc: 0.5539 - val_loss: 504000.6159 - val_acc: 0.5563\n",
      "Epoch 282/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6570 - acc: 0.5523 - val_loss: 504000.6159 - val_acc: 0.5582\n",
      "Epoch 283/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6592 - acc: 0.5537 - val_loss: 504000.6159 - val_acc: 0.5539\n",
      "Epoch 284/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6563 - acc: 0.5538 - val_loss: 504000.6159 - val_acc: 0.5563\n",
      "Epoch 285/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6583 - acc: 0.5527 - val_loss: 504000.6159 - val_acc: 0.5597\n",
      "Epoch 286/500\n",
      "9697/9697 [==============================] - 1s 74us/step - loss: 505088.6579 - acc: 0.5531 - val_loss: 504000.6159 - val_acc: 0.5597\n",
      "Epoch 287/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6570 - acc: 0.5540 - val_loss: 504000.6159 - val_acc: 0.5597\n",
      "Epoch 288/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6580 - acc: 0.5521 - val_loss: 504000.6159 - val_acc: 0.5592\n",
      "Epoch 289/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6576 - acc: 0.5536 - val_loss: 504000.6159 - val_acc: 0.5573\n",
      "Epoch 290/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6555 - acc: 0.5541 - val_loss: 504000.6159 - val_acc: 0.5597\n",
      "Epoch 291/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6573 - acc: 0.5551 - val_loss: 504000.6159 - val_acc: 0.5606\n",
      "Epoch 292/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6578 - acc: 0.5533 - val_loss: 504000.6159 - val_acc: 0.5582\n",
      "Epoch 293/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6591 - acc: 0.5557 - val_loss: 504000.6159 - val_acc: 0.5544\n",
      "Epoch 294/500\n",
      "9697/9697 [==============================] - 1s 80us/step - loss: 505088.6576 - acc: 0.5549 - val_loss: 504000.6159 - val_acc: 0.5602\n",
      "Epoch 295/500\n",
      "9697/9697 [==============================] - 1s 74us/step - loss: 505088.6588 - acc: 0.5532 - val_loss: 504000.6159 - val_acc: 0.5577\n",
      "Epoch 296/500\n",
      "9697/9697 [==============================] - 1s 74us/step - loss: 505088.6586 - acc: 0.5542 - val_loss: 504000.6159 - val_acc: 0.5597\n",
      "Epoch 297/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6581 - acc: 0.5535 - val_loss: 504000.6159 - val_acc: 0.5602\n",
      "Epoch 298/500\n",
      "9697/9697 [==============================] - 1s 74us/step - loss: 505088.6571 - acc: 0.5529 - val_loss: 504000.6159 - val_acc: 0.5602\n",
      "Epoch 299/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6564 - acc: 0.5555 - val_loss: 504000.6159 - val_acc: 0.5606\n",
      "Epoch 300/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6578 - acc: 0.5531 - val_loss: 504000.6159 - val_acc: 0.5558\n",
      "Epoch 301/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6576 - acc: 0.5551 - val_loss: 504000.6159 - val_acc: 0.5587\n",
      "Epoch 302/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6561 - acc: 0.5557 - val_loss: 504000.6159 - val_acc: 0.5563\n",
      "Epoch 303/500\n",
      "9697/9697 [==============================] - 1s 72us/step - loss: 505088.6574 - acc: 0.5568 - val_loss: 504000.6159 - val_acc: 0.5606\n",
      "Epoch 304/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6586 - acc: 0.5560 - val_loss: 504000.6159 - val_acc: 0.5587\n",
      "Epoch 305/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6575 - acc: 0.5527 - val_loss: 504000.6159 - val_acc: 0.5568\n",
      "Epoch 306/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6563 - acc: 0.5555 - val_loss: 504000.6159 - val_acc: 0.5558\n",
      "Epoch 307/500\n",
      "9697/9697 [==============================] - 1s 74us/step - loss: 505088.6568 - acc: 0.5555 - val_loss: 504000.6159 - val_acc: 0.5621\n",
      "Epoch 308/500\n",
      "9697/9697 [==============================] - 1s 74us/step - loss: 505088.6586 - acc: 0.5551 - val_loss: 504000.6159 - val_acc: 0.5611\n",
      "Epoch 309/500\n",
      "9697/9697 [==============================] - 1s 74us/step - loss: 505088.6584 - acc: 0.5575 - val_loss: 504000.6159 - val_acc: 0.5606\n",
      "Epoch 310/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6575 - acc: 0.5554 - val_loss: 504000.6159 - val_acc: 0.5573\n",
      "Epoch 311/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6575 - acc: 0.5555 - val_loss: 504000.6159 - val_acc: 0.5597\n",
      "Epoch 312/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6571 - acc: 0.5551 - val_loss: 504000.6159 - val_acc: 0.5577\n",
      "Epoch 313/500\n",
      "9697/9697 [==============================] - 1s 75us/step - loss: 505088.6578 - acc: 0.5549 - val_loss: 504000.6159 - val_acc: 0.5592\n",
      "Epoch 314/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6579 - acc: 0.5550 - val_loss: 504000.6159 - val_acc: 0.5606\n",
      "Epoch 315/500\n",
      "9697/9697 [==============================] - 1s 72us/step - loss: 505088.6574 - acc: 0.5570 - val_loss: 504000.6159 - val_acc: 0.5549\n",
      "Epoch 316/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6580 - acc: 0.5522 - val_loss: 504000.6159 - val_acc: 0.5573\n",
      "Epoch 317/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6576 - acc: 0.5560 - val_loss: 504000.6159 - val_acc: 0.5606\n",
      "Epoch 318/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6569 - acc: 0.5550 - val_loss: 504000.6159 - val_acc: 0.5621\n",
      "Epoch 319/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6576 - acc: 0.5565 - val_loss: 504000.6159 - val_acc: 0.5587\n",
      "Epoch 320/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6584 - acc: 0.5553 - val_loss: 504000.6159 - val_acc: 0.5602\n",
      "Epoch 321/500\n",
      "9697/9697 [==============================] - 1s 77us/step - loss: 505088.6564 - acc: 0.5538 - val_loss: 504000.6159 - val_acc: 0.5626\n",
      "Epoch 322/500\n",
      "9697/9697 [==============================] - 1s 72us/step - loss: 505088.6576 - acc: 0.5569 - val_loss: 504000.6159 - val_acc: 0.5582\n",
      "Epoch 323/500\n",
      "9697/9697 [==============================] - 1s 74us/step - loss: 505088.6595 - acc: 0.5560 - val_loss: 504000.6159 - val_acc: 0.5592\n",
      "Epoch 324/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6582 - acc: 0.5568 - val_loss: 504000.6159 - val_acc: 0.5640\n",
      "Epoch 325/500\n",
      "9697/9697 [==============================] - 1s 74us/step - loss: 505088.6591 - acc: 0.5555 - val_loss: 504000.6159 - val_acc: 0.5592\n",
      "Epoch 326/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6588 - acc: 0.5572 - val_loss: 504000.6159 - val_acc: 0.5630\n",
      "Epoch 327/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6571 - acc: 0.5547 - val_loss: 504000.6159 - val_acc: 0.5597\n",
      "Epoch 328/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6564 - acc: 0.5567 - val_loss: 504000.6159 - val_acc: 0.5563\n",
      "Epoch 329/500\n",
      "9697/9697 [==============================] - 1s 72us/step - loss: 505088.6569 - acc: 0.5559 - val_loss: 504000.6159 - val_acc: 0.5616\n",
      "Epoch 330/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6580 - acc: 0.5572 - val_loss: 504000.6159 - val_acc: 0.5582\n",
      "Epoch 331/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6568 - acc: 0.5577 - val_loss: 504000.6159 - val_acc: 0.5606\n",
      "Epoch 332/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6561 - acc: 0.5551 - val_loss: 504000.6159 - val_acc: 0.5606\n",
      "Epoch 333/500\n",
      "9697/9697 [==============================] - 1s 74us/step - loss: 505088.6580 - acc: 0.5567 - val_loss: 504000.6159 - val_acc: 0.5592\n",
      "Epoch 334/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6566 - acc: 0.5552 - val_loss: 504000.6159 - val_acc: 0.5597\n",
      "Epoch 335/500\n",
      "9697/9697 [==============================] - 1s 74us/step - loss: 505088.6579 - acc: 0.5573 - val_loss: 504000.6159 - val_acc: 0.5606\n",
      "Epoch 336/500\n",
      "9697/9697 [==============================] - 1s 72us/step - loss: 505088.6577 - acc: 0.5567 - val_loss: 504000.6159 - val_acc: 0.5573\n",
      "Epoch 337/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6559 - acc: 0.5562 - val_loss: 504000.6159 - val_acc: 0.5602\n",
      "Epoch 338/500\n",
      "9697/9697 [==============================] - 1s 74us/step - loss: 505088.6573 - acc: 0.5574 - val_loss: 504000.6159 - val_acc: 0.5568\n",
      "Epoch 339/500\n",
      "9697/9697 [==============================] - 1s 72us/step - loss: 505088.6581 - acc: 0.5563 - val_loss: 504000.6159 - val_acc: 0.5592\n",
      "Epoch 340/500\n",
      "9697/9697 [==============================] - 1s 72us/step - loss: 505088.6550 - acc: 0.5589 - val_loss: 504000.6159 - val_acc: 0.5611\n",
      "Epoch 341/500\n",
      "9697/9697 [==============================] - 1s 74us/step - loss: 505088.6556 - acc: 0.5555 - val_loss: 504000.6159 - val_acc: 0.5573\n",
      "Epoch 342/500\n",
      "9697/9697 [==============================] - 1s 74us/step - loss: 505088.6566 - acc: 0.5569 - val_loss: 504000.6159 - val_acc: 0.5582\n",
      "Epoch 343/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6566 - acc: 0.5573 - val_loss: 504000.6159 - val_acc: 0.5563\n",
      "Epoch 344/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6572 - acc: 0.5553 - val_loss: 504000.6159 - val_acc: 0.5621\n",
      "Epoch 345/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6552 - acc: 0.5578 - val_loss: 504000.6159 - val_acc: 0.5621\n",
      "Epoch 346/500\n",
      "9697/9697 [==============================] - 1s 74us/step - loss: 505088.6568 - acc: 0.5558 - val_loss: 504000.6159 - val_acc: 0.5568\n",
      "Epoch 347/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6589 - acc: 0.5567 - val_loss: 504000.6159 - val_acc: 0.5592\n",
      "Epoch 348/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6574 - acc: 0.5564 - val_loss: 504000.6159 - val_acc: 0.5597\n",
      "Epoch 349/500\n",
      "9697/9697 [==============================] - 1s 74us/step - loss: 505088.6580 - acc: 0.5567 - val_loss: 504000.6159 - val_acc: 0.5587\n",
      "Epoch 350/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6591 - acc: 0.5586 - val_loss: 504000.6159 - val_acc: 0.5597\n",
      "Epoch 351/500\n",
      "9697/9697 [==============================] - 1s 74us/step - loss: 505088.6576 - acc: 0.5584 - val_loss: 504000.6159 - val_acc: 0.5611\n",
      "Epoch 352/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6573 - acc: 0.5557 - val_loss: 504000.6159 - val_acc: 0.5606\n",
      "Epoch 353/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6565 - acc: 0.5578 - val_loss: 504000.6159 - val_acc: 0.5563\n",
      "Epoch 354/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6592 - acc: 0.5565 - val_loss: 504000.6159 - val_acc: 0.5611\n",
      "Epoch 355/500\n",
      "9697/9697 [==============================] - 1s 74us/step - loss: 505088.6576 - acc: 0.5568 - val_loss: 504000.6159 - val_acc: 0.5626\n",
      "Epoch 356/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6550 - acc: 0.5591 - val_loss: 504000.6159 - val_acc: 0.5606\n",
      "Epoch 357/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6568 - acc: 0.5595 - val_loss: 504000.6159 - val_acc: 0.5602\n",
      "Epoch 358/500\n",
      "9697/9697 [==============================] - 1s 74us/step - loss: 505088.6563 - acc: 0.5592 - val_loss: 504000.6159 - val_acc: 0.5597\n",
      "Epoch 359/500\n",
      "9697/9697 [==============================] - 1s 74us/step - loss: 505088.6581 - acc: 0.5569 - val_loss: 504000.6159 - val_acc: 0.5616\n",
      "Epoch 360/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6560 - acc: 0.5586 - val_loss: 504000.6159 - val_acc: 0.5587\n",
      "Epoch 361/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6578 - acc: 0.5571 - val_loss: 504000.6159 - val_acc: 0.5621\n",
      "Epoch 362/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6586 - acc: 0.5551 - val_loss: 504000.6159 - val_acc: 0.5616\n",
      "Epoch 363/500\n",
      "9697/9697 [==============================] - 1s 74us/step - loss: 505088.6556 - acc: 0.5585 - val_loss: 504000.6159 - val_acc: 0.5606\n",
      "Epoch 364/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6565 - acc: 0.5565 - val_loss: 504000.6159 - val_acc: 0.5592\n",
      "Epoch 365/500\n",
      "9697/9697 [==============================] - 1s 74us/step - loss: 505088.6564 - acc: 0.5582 - val_loss: 504000.6159 - val_acc: 0.5611\n",
      "Epoch 366/500\n",
      "9697/9697 [==============================] - 1s 74us/step - loss: 505088.6591 - acc: 0.5577 - val_loss: 504000.6159 - val_acc: 0.5606\n",
      "Epoch 367/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6564 - acc: 0.5596 - val_loss: 504000.6159 - val_acc: 0.5611\n",
      "Epoch 368/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6564 - acc: 0.5560 - val_loss: 504000.6159 - val_acc: 0.5573\n",
      "Epoch 369/500\n",
      "9697/9697 [==============================] - 1s 74us/step - loss: 505088.6581 - acc: 0.5565 - val_loss: 504000.6159 - val_acc: 0.5640\n",
      "Epoch 370/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6585 - acc: 0.5601 - val_loss: 504000.6159 - val_acc: 0.5602\n",
      "Epoch 371/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6557 - acc: 0.5584 - val_loss: 504000.6159 - val_acc: 0.5592\n",
      "Epoch 372/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6574 - acc: 0.5581 - val_loss: 504000.6159 - val_acc: 0.5630\n",
      "Epoch 373/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6585 - acc: 0.5582 - val_loss: 504000.6159 - val_acc: 0.5597\n",
      "Epoch 374/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6559 - acc: 0.5580 - val_loss: 504000.6159 - val_acc: 0.5626\n",
      "Epoch 375/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6585 - acc: 0.5588 - val_loss: 504000.6159 - val_acc: 0.5630\n",
      "Epoch 376/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6570 - acc: 0.5566 - val_loss: 504000.6159 - val_acc: 0.5640\n",
      "Epoch 377/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6576 - acc: 0.5587 - val_loss: 504000.6159 - val_acc: 0.5621\n",
      "Epoch 378/500\n",
      "9697/9697 [==============================] - 1s 74us/step - loss: 505088.6571 - acc: 0.5585 - val_loss: 504000.6159 - val_acc: 0.5621\n",
      "Epoch 379/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6568 - acc: 0.5571 - val_loss: 504000.6159 - val_acc: 0.5577\n",
      "Epoch 380/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6581 - acc: 0.5589 - val_loss: 504000.6159 - val_acc: 0.5611\n",
      "Epoch 381/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6579 - acc: 0.5589 - val_loss: 504000.6159 - val_acc: 0.5597\n",
      "Epoch 382/500\n",
      "9697/9697 [==============================] - 1s 74us/step - loss: 505088.6604 - acc: 0.5576 - val_loss: 504000.6159 - val_acc: 0.5626\n",
      "Epoch 383/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6566 - acc: 0.5579 - val_loss: 504000.6159 - val_acc: 0.5635\n",
      "Epoch 384/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6567 - acc: 0.5580 - val_loss: 504000.6159 - val_acc: 0.5645\n",
      "Epoch 385/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6566 - acc: 0.5590 - val_loss: 504000.6159 - val_acc: 0.5606\n",
      "Epoch 386/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9697/9697 [==============================] - 1s 74us/step - loss: 505088.6576 - acc: 0.5583 - val_loss: 504000.6159 - val_acc: 0.5553\n",
      "Epoch 387/500\n",
      "9697/9697 [==============================] - 1s 74us/step - loss: 505088.6583 - acc: 0.5577 - val_loss: 504000.6159 - val_acc: 0.5630\n",
      "Epoch 388/500\n",
      "9697/9697 [==============================] - 1s 74us/step - loss: 505088.6571 - acc: 0.5582 - val_loss: 504000.6159 - val_acc: 0.5606\n",
      "Epoch 389/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6576 - acc: 0.5597 - val_loss: 504000.6159 - val_acc: 0.5626\n",
      "Epoch 390/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6564 - acc: 0.5585 - val_loss: 504000.6159 - val_acc: 0.5616\n",
      "Epoch 391/500\n",
      "9697/9697 [==============================] - 1s 74us/step - loss: 505088.6563 - acc: 0.5591 - val_loss: 504000.6159 - val_acc: 0.5645\n",
      "Epoch 392/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6560 - acc: 0.5586 - val_loss: 504000.6159 - val_acc: 0.5616\n",
      "Epoch 393/500\n",
      "9697/9697 [==============================] - 1s 74us/step - loss: 505088.6563 - acc: 0.5584 - val_loss: 504000.6159 - val_acc: 0.5626\n",
      "Epoch 394/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6572 - acc: 0.5602 - val_loss: 504000.6159 - val_acc: 0.5635\n",
      "Epoch 395/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6575 - acc: 0.5599 - val_loss: 504000.6159 - val_acc: 0.5635\n",
      "Epoch 396/500\n",
      "9697/9697 [==============================] - 1s 75us/step - loss: 505088.6569 - acc: 0.5584 - val_loss: 504000.6159 - val_acc: 0.5611\n",
      "Epoch 397/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6581 - acc: 0.5585 - val_loss: 504000.6159 - val_acc: 0.5602\n",
      "Epoch 398/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6587 - acc: 0.5601 - val_loss: 504000.6159 - val_acc: 0.5640\n",
      "Epoch 399/500\n",
      "9697/9697 [==============================] - 1s 72us/step - loss: 505088.6584 - acc: 0.5577 - val_loss: 504000.6159 - val_acc: 0.5616\n",
      "Epoch 400/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6595 - acc: 0.5596 - val_loss: 504000.6159 - val_acc: 0.5616\n",
      "Epoch 401/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6565 - acc: 0.5591 - val_loss: 504000.6159 - val_acc: 0.5669\n",
      "Epoch 402/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6564 - acc: 0.5586 - val_loss: 504000.6159 - val_acc: 0.5645\n",
      "Epoch 403/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6583 - acc: 0.5591 - val_loss: 504000.6159 - val_acc: 0.5650\n",
      "Epoch 404/500\n",
      "9697/9697 [==============================] - 1s 91us/step - loss: 505088.6577 - acc: 0.5593 - val_loss: 504000.6159 - val_acc: 0.5650\n",
      "Epoch 405/500\n",
      "9697/9697 [==============================] - 1s 119us/step - loss: 505088.6566 - acc: 0.5601 - val_loss: 504000.6159 - val_acc: 0.5602\n",
      "Epoch 406/500\n",
      "9697/9697 [==============================] - 1s 77us/step - loss: 505088.6581 - acc: 0.5597 - val_loss: 504000.6159 - val_acc: 0.5650\n",
      "Epoch 407/500\n",
      "9697/9697 [==============================] - 1s 75us/step - loss: 505088.6580 - acc: 0.5584 - val_loss: 504000.6159 - val_acc: 0.5616\n",
      "Epoch 408/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6570 - acc: 0.5593 - val_loss: 504000.6159 - val_acc: 0.5635\n",
      "Epoch 409/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6582 - acc: 0.5596 - val_loss: 504000.6159 - val_acc: 0.5602\n",
      "Epoch 410/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6563 - acc: 0.5592 - val_loss: 504000.6159 - val_acc: 0.5592\n",
      "Epoch 411/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6574 - acc: 0.5599 - val_loss: 504000.6159 - val_acc: 0.5626\n",
      "Epoch 412/500\n",
      "9697/9697 [==============================] - 1s 87us/step - loss: 505088.6564 - acc: 0.5602 - val_loss: 504000.6159 - val_acc: 0.5635\n",
      "Epoch 413/500\n",
      "9697/9697 [==============================] - 1s 81us/step - loss: 505088.6560 - acc: 0.5589 - val_loss: 504000.6159 - val_acc: 0.5630\n",
      "Epoch 414/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6565 - acc: 0.5597 - val_loss: 504000.6159 - val_acc: 0.5616\n",
      "Epoch 415/500\n",
      "9697/9697 [==============================] - 1s 74us/step - loss: 505088.6586 - acc: 0.5613 - val_loss: 504000.6159 - val_acc: 0.5650\n",
      "Epoch 416/500\n",
      "9697/9697 [==============================] - 1s 74us/step - loss: 505088.6578 - acc: 0.5603 - val_loss: 504000.6159 - val_acc: 0.5650\n",
      "Epoch 417/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6569 - acc: 0.5604 - val_loss: 504000.6159 - val_acc: 0.5669\n",
      "Epoch 418/500\n",
      "9697/9697 [==============================] - 1s 74us/step - loss: 505088.6581 - acc: 0.5584 - val_loss: 504000.6159 - val_acc: 0.5654\n",
      "Epoch 419/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6578 - acc: 0.5602 - val_loss: 504000.6159 - val_acc: 0.5630\n",
      "Epoch 420/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6565 - acc: 0.5595 - val_loss: 504000.6159 - val_acc: 0.5645\n",
      "Epoch 421/500\n",
      "9697/9697 [==============================] - 1s 74us/step - loss: 505088.6580 - acc: 0.5595 - val_loss: 504000.6159 - val_acc: 0.5650\n",
      "Epoch 422/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6569 - acc: 0.5603 - val_loss: 504000.6159 - val_acc: 0.5659\n",
      "Epoch 423/500\n",
      "9697/9697 [==============================] - 1s 74us/step - loss: 505088.6566 - acc: 0.5602 - val_loss: 504000.6159 - val_acc: 0.5635\n",
      "Epoch 424/500\n",
      "9697/9697 [==============================] - 1s 75us/step - loss: 505088.6558 - acc: 0.5597 - val_loss: 504000.6159 - val_acc: 0.5616\n",
      "Epoch 425/500\n",
      "9697/9697 [==============================] - 1s 74us/step - loss: 505088.6573 - acc: 0.5607 - val_loss: 504000.6159 - val_acc: 0.5611\n",
      "Epoch 426/500\n",
      "9697/9697 [==============================] - 1s 74us/step - loss: 505088.6576 - acc: 0.5601 - val_loss: 504000.6159 - val_acc: 0.5664\n",
      "Epoch 427/500\n",
      "9697/9697 [==============================] - 1s 74us/step - loss: 505088.6593 - acc: 0.5609 - val_loss: 504000.6159 - val_acc: 0.5650\n",
      "Epoch 428/500\n",
      "9697/9697 [==============================] - 1s 74us/step - loss: 505088.6572 - acc: 0.5599 - val_loss: 504000.6159 - val_acc: 0.5664\n",
      "Epoch 429/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6578 - acc: 0.5608 - val_loss: 504000.6159 - val_acc: 0.5640\n",
      "Epoch 430/500\n",
      "9697/9697 [==============================] - 1s 74us/step - loss: 505088.6575 - acc: 0.5602 - val_loss: 504000.6159 - val_acc: 0.5659\n",
      "Epoch 431/500\n",
      "9697/9697 [==============================] - 1s 72us/step - loss: 505088.6567 - acc: 0.5606 - val_loss: 504000.6159 - val_acc: 0.5626\n",
      "Epoch 432/500\n",
      "9697/9697 [==============================] - 1s 74us/step - loss: 505088.6567 - acc: 0.5610 - val_loss: 504000.6159 - val_acc: 0.5635\n",
      "Epoch 433/500\n",
      "9697/9697 [==============================] - 1s 74us/step - loss: 505088.6584 - acc: 0.5614 - val_loss: 504000.6159 - val_acc: 0.5621\n",
      "Epoch 434/500\n",
      "9697/9697 [==============================] - 1s 81us/step - loss: 505088.6569 - acc: 0.5586 - val_loss: 504000.6159 - val_acc: 0.5635\n",
      "Epoch 435/500\n",
      "9697/9697 [==============================] - 1s 76us/step - loss: 505088.6568 - acc: 0.5601 - val_loss: 504000.6159 - val_acc: 0.5635\n",
      "Epoch 436/500\n",
      "9697/9697 [==============================] - 1s 90us/step - loss: 505088.6584 - acc: 0.5609 - val_loss: 504000.6159 - val_acc: 0.5606\n",
      "Epoch 437/500\n",
      "9697/9697 [==============================] - 1s 74us/step - loss: 505088.6568 - acc: 0.5603 - val_loss: 504000.6159 - val_acc: 0.5650\n",
      "Epoch 438/500\n",
      "9697/9697 [==============================] - 1s 110us/step - loss: 505088.6564 - acc: 0.5604 - val_loss: 504000.6159 - val_acc: 0.5664\n",
      "Epoch 439/500\n",
      "9697/9697 [==============================] - 1s 82us/step - loss: 505088.6578 - acc: 0.5599 - val_loss: 504000.6159 - val_acc: 0.5645\n",
      "Epoch 440/500\n",
      "9697/9697 [==============================] - 1s 99us/step - loss: 505088.6580 - acc: 0.5605 - val_loss: 504000.6159 - val_acc: 0.5611\n",
      "Epoch 441/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9697/9697 [==============================] - 1s 77us/step - loss: 505088.6573 - acc: 0.5608 - val_loss: 504000.6159 - val_acc: 0.5664\n",
      "Epoch 442/500\n",
      "9697/9697 [==============================] - 1s 75us/step - loss: 505088.6576 - acc: 0.5612 - val_loss: 504000.6159 - val_acc: 0.5630\n",
      "Epoch 443/500\n",
      "9697/9697 [==============================] - 1s 74us/step - loss: 505088.6559 - acc: 0.5624 - val_loss: 504000.6159 - val_acc: 0.5659\n",
      "Epoch 444/500\n",
      "9697/9697 [==============================] - 1s 75us/step - loss: 505088.6549 - acc: 0.5598 - val_loss: 504000.6159 - val_acc: 0.5659\n",
      "Epoch 445/500\n",
      "9697/9697 [==============================] - 1s 74us/step - loss: 505088.6570 - acc: 0.5615 - val_loss: 504000.6159 - val_acc: 0.5650\n",
      "Epoch 446/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6564 - acc: 0.5608 - val_loss: 504000.6159 - val_acc: 0.5650\n",
      "Epoch 447/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6557 - acc: 0.5620 - val_loss: 504000.6159 - val_acc: 0.5630\n",
      "Epoch 448/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6572 - acc: 0.5603 - val_loss: 504000.6159 - val_acc: 0.5645\n",
      "Epoch 449/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6583 - acc: 0.5614 - val_loss: 504000.6159 - val_acc: 0.5645\n",
      "Epoch 450/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6590 - acc: 0.5616 - val_loss: 504000.6159 - val_acc: 0.5640\n",
      "Epoch 451/500\n",
      "9697/9697 [==============================] - 1s 75us/step - loss: 505088.6573 - acc: 0.5618 - val_loss: 504000.6159 - val_acc: 0.5650\n",
      "Epoch 452/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6580 - acc: 0.5612 - val_loss: 504000.6159 - val_acc: 0.5645\n",
      "Epoch 453/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6564 - acc: 0.5620 - val_loss: 504000.6159 - val_acc: 0.5630\n",
      "Epoch 454/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6580 - acc: 0.5617 - val_loss: 504000.6159 - val_acc: 0.5654\n",
      "Epoch 455/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6576 - acc: 0.5607 - val_loss: 504000.6159 - val_acc: 0.5626\n",
      "Epoch 456/500\n",
      "9697/9697 [==============================] - 1s 72us/step - loss: 505088.6562 - acc: 0.5598 - val_loss: 504000.6159 - val_acc: 0.5621\n",
      "Epoch 457/500\n",
      "9697/9697 [==============================] - 1s 72us/step - loss: 505088.6567 - acc: 0.5617 - val_loss: 504000.6159 - val_acc: 0.5679\n",
      "Epoch 458/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6562 - acc: 0.5611 - val_loss: 504000.6159 - val_acc: 0.5621\n",
      "Epoch 459/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6587 - acc: 0.5610 - val_loss: 504000.6159 - val_acc: 0.5669\n",
      "Epoch 460/500\n",
      "9697/9697 [==============================] - 1s 72us/step - loss: 505088.6574 - acc: 0.5619 - val_loss: 504000.6159 - val_acc: 0.5683\n",
      "Epoch 461/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6568 - acc: 0.5628 - val_loss: 504000.6159 - val_acc: 0.5659\n",
      "Epoch 462/500\n",
      "9697/9697 [==============================] - 1s 74us/step - loss: 505088.6580 - acc: 0.5617 - val_loss: 504000.6159 - val_acc: 0.5630\n",
      "Epoch 463/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6564 - acc: 0.5610 - val_loss: 504000.6159 - val_acc: 0.5654\n",
      "Epoch 464/500\n",
      "9697/9697 [==============================] - 1s 74us/step - loss: 505088.6556 - acc: 0.5615 - val_loss: 504000.6159 - val_acc: 0.5635\n",
      "Epoch 465/500\n",
      "9697/9697 [==============================] - 1s 74us/step - loss: 505088.6573 - acc: 0.5617 - val_loss: 504000.6159 - val_acc: 0.5659\n",
      "Epoch 466/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6545 - acc: 0.5620 - val_loss: 504000.6159 - val_acc: 0.5650\n",
      "Epoch 467/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6571 - acc: 0.5620 - val_loss: 504000.6159 - val_acc: 0.5650\n",
      "Epoch 468/500\n",
      "9697/9697 [==============================] - 1s 74us/step - loss: 505088.6560 - acc: 0.5624 - val_loss: 504000.6159 - val_acc: 0.5626\n",
      "Epoch 469/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6561 - acc: 0.5614 - val_loss: 504000.6159 - val_acc: 0.5674\n",
      "Epoch 470/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6586 - acc: 0.5618 - val_loss: 504000.6159 - val_acc: 0.5654\n",
      "Epoch 471/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6568 - acc: 0.5617 - val_loss: 504000.6159 - val_acc: 0.5674\n",
      "Epoch 472/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6573 - acc: 0.5625 - val_loss: 504000.6159 - val_acc: 0.5654\n",
      "Epoch 473/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6570 - acc: 0.5615 - val_loss: 504000.6159 - val_acc: 0.5630\n",
      "Epoch 474/500\n",
      "9697/9697 [==============================] - 1s 72us/step - loss: 505088.6584 - acc: 0.5623 - val_loss: 504000.6159 - val_acc: 0.5674\n",
      "Epoch 475/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6586 - acc: 0.5617 - val_loss: 504000.6159 - val_acc: 0.5630\n",
      "Epoch 476/500\n",
      "9697/9697 [==============================] - 1s 74us/step - loss: 505088.6577 - acc: 0.5614 - val_loss: 504000.6159 - val_acc: 0.5635\n",
      "Epoch 477/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6581 - acc: 0.5617 - val_loss: 504000.6159 - val_acc: 0.5626\n",
      "Epoch 478/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6566 - acc: 0.5625 - val_loss: 504000.6159 - val_acc: 0.5698\n",
      "Epoch 479/500\n",
      "9697/9697 [==============================] - 1s 75us/step - loss: 505088.6566 - acc: 0.5629 - val_loss: 504000.6159 - val_acc: 0.5635\n",
      "Epoch 480/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6577 - acc: 0.5630 - val_loss: 504000.6159 - val_acc: 0.5630\n",
      "Epoch 481/500\n",
      "9697/9697 [==============================] - 1s 74us/step - loss: 505088.6561 - acc: 0.5613 - val_loss: 504000.6159 - val_acc: 0.5650\n",
      "Epoch 482/500\n",
      "9697/9697 [==============================] - 1s 73us/step - loss: 505088.6585 - acc: 0.5631 - val_loss: 504000.6159 - val_acc: 0.5650\n",
      "Epoch 483/500\n",
      "9697/9697 [==============================] - 1s 85us/step - loss: 505088.6557 - acc: 0.5614 - val_loss: 504000.6159 - val_acc: 0.5650\n",
      "Epoch 484/500\n",
      "9697/9697 [==============================] - 1s 74us/step - loss: 505088.6578 - acc: 0.5630 - val_loss: 504000.6159 - val_acc: 0.5659\n",
      "Epoch 485/500\n",
      "9697/9697 [==============================] - 1s 82us/step - loss: 505088.6580 - acc: 0.5607 - val_loss: 504000.6159 - val_acc: 0.5679\n",
      "Epoch 486/500\n",
      "9697/9697 [==============================] - 1s 126us/step - loss: 505088.6565 - acc: 0.5612 - val_loss: 504000.6159 - val_acc: 0.5645\n",
      "Epoch 487/500\n",
      "9697/9697 [==============================] - 1s 75us/step - loss: 505088.6561 - acc: 0.5612 - val_loss: 504000.6159 - val_acc: 0.5674\n",
      "Epoch 488/500\n",
      "9697/9697 [==============================] - 1s 81us/step - loss: 505088.6571 - acc: 0.5607 - val_loss: 504000.6159 - val_acc: 0.5650\n",
      "Epoch 489/500\n",
      "9697/9697 [==============================] - 1s 78us/step - loss: 505088.6574 - acc: 0.5632 - val_loss: 504000.6159 - val_acc: 0.5654\n",
      "Epoch 490/500\n",
      "9697/9697 [==============================] - 1s 79us/step - loss: 505088.6578 - acc: 0.5623 - val_loss: 504000.6159 - val_acc: 0.5669\n",
      "Epoch 491/500\n",
      "9697/9697 [==============================] - 1s 79us/step - loss: 505088.6581 - acc: 0.5620 - val_loss: 504000.6159 - val_acc: 0.5650\n",
      "Epoch 492/500\n",
      "9697/9697 [==============================] - 1s 78us/step - loss: 505088.6573 - acc: 0.5632 - val_loss: 504000.6159 - val_acc: 0.5650\n",
      "Epoch 493/500\n",
      "9697/9697 [==============================] - 1s 76us/step - loss: 505088.6570 - acc: 0.5630 - val_loss: 504000.6159 - val_acc: 0.5669\n",
      "Epoch 494/500\n",
      "9697/9697 [==============================] - 1s 76us/step - loss: 505088.6567 - acc: 0.5637 - val_loss: 504000.6159 - val_acc: 0.5630\n",
      "Epoch 495/500\n",
      "9697/9697 [==============================] - 1s 134us/step - loss: 505088.6575 - acc: 0.5619 - val_loss: 504000.6159 - val_acc: 0.5645\n",
      "Epoch 496/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9697/9697 [==============================] - 1s 116us/step - loss: 505088.6583 - acc: 0.5634 - val_loss: 504000.6159 - val_acc: 0.5654\n",
      "Epoch 497/500\n",
      "9697/9697 [==============================] - 1s 88us/step - loss: 505088.6577 - acc: 0.5619 - val_loss: 504000.6159 - val_acc: 0.5640\n",
      "Epoch 498/500\n",
      "9697/9697 [==============================] - 1s 85us/step - loss: 505088.6598 - acc: 0.5622 - val_loss: 504000.6159 - val_acc: 0.5654\n",
      "Epoch 499/500\n",
      "9697/9697 [==============================] - 1s 85us/step - loss: 505088.6566 - acc: 0.5634 - val_loss: 504000.6159 - val_acc: 0.5674\n",
      "Epoch 500/500\n",
      "9697/9697 [==============================] - 1s 122us/step - loss: 505088.6585 - acc: 0.5644 - val_loss: 504000.6159 - val_acc: 0.5650\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train, y_train,\n",
    "          batch_size=32, epochs=500,\n",
    "          validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, ax1 = plt.subplots()\n",
    "f.set_figheight(8)\n",
    "f.set_figwidth(15)\n",
    "\n",
    "plt.plot(hist.history['acc'])\n",
    "plt.plot(hist.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
