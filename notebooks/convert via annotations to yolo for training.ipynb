{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from urllib import parse\n",
    "from urllib.request import urlopen\n",
    "from PIL import Image, ImageDraw\n",
    "import os, shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIXELS_X = 910\n",
    "PIXELS_Y = 910  # equal to the number of scan lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = '/Users/darylwilding-mcbride/Google Drive/Personal/PhD/source/yolo-tile-labelling'\n",
    "TRAINING_SET_BASE_DIR = '{}/training'.format(BASE_DIR)\n",
    "PRE_ASSIGNED_FILES_DIR = '{}/pre-assigned'.format(TRAINING_SET_BASE_DIR)\n",
    "OVERLAY_FILES_DIR = '{}/overlays'.format(TRAINING_SET_BASE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(PRE_ASSIGNED_FILES_DIR):\n",
    "    shutil.rmtree(PRE_ASSIGNED_FILES_DIR)\n",
    "os.makedirs(PRE_ASSIGNED_FILES_DIR)\n",
    "\n",
    "if os.path.exists(OVERLAY_FILES_DIR):\n",
    "    shutil.rmtree(OVERLAY_FILES_DIR)\n",
    "os.makedirs(OVERLAY_FILES_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "annotations_file_name = '{}/annotations/via_export_json_aw.json'.format(BASE_DIR)\n",
    "with open(annotations_file_name) as annotations_file:\n",
    "    annotations = json.load(annotations_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://spectra-server-lb-1653892276.ap-southeast-2.elb.amazonaws.com/tile/33/frame/1889'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = list(annotations.items())[0][1]['filename']\n",
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in YOLO a small object is smaller than 16x16 @ 416x416 image size.\n",
    "SMALL_OBJECT_W = SMALL_OBJECT_H = 16/416"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 out of 1254 objects are small.\n"
     ]
    }
   ],
   "source": [
    "tile_list = []\n",
    "classes_d = {}\n",
    "small_objects = 0\n",
    "total_objects = 0\n",
    "for tile in list(annotations.items()):\n",
    "    tile_d = tile[1]\n",
    "    tile_regions = tile_d['regions']\n",
    "    # process this tile if there are annotations for it\n",
    "    if len(tile_regions) > 0:\n",
    "        # load the tile\n",
    "        tile_url = tile_d['filename']  # this is the URL so we need to download it\n",
    "        tile = Image.open(urlopen(tile_url))\n",
    "\n",
    "        # determine the frame_id and tile_id\n",
    "        path_split = parse.urlsplit(tile_url).path.split('/')\n",
    "        tile_idx = int(path_split[2])\n",
    "        frame_id = int(path_split[4])\n",
    "\n",
    "        # set the file names\n",
    "        tile_filename = 'frame-{}-tile-{}.png'.format(frame_id, tile_idx)\n",
    "        tile_path = '{}/{}'.format(PRE_ASSIGNED_FILES_DIR, tile_filename)\n",
    "        annotations_filename = 'frame-{}-tile-{}.txt'.format(frame_id, tile_idx)\n",
    "        annotations_path = '{}/{}'.format(PRE_ASSIGNED_FILES_DIR, annotations_filename)\n",
    "        overlay_filename = '{}/frame-{}-tile-{}.png'.format(OVERLAY_FILES_DIR, frame_id, tile_idx)\n",
    "        tile_list.append((tile_filename, annotations_filename))\n",
    "\n",
    "        # save this tile\n",
    "        tile.save(tile_path)\n",
    "        \n",
    "        # get a drawing context for the tile\n",
    "        draw = ImageDraw.Draw(tile)\n",
    "\n",
    "        # render the annotations\n",
    "        feature_coordinates = []\n",
    "        total_objects += len(tile_regions)\n",
    "        for region in tile_regions:\n",
    "            shape_attributes = region['shape_attributes']\n",
    "            x = shape_attributes['x']\n",
    "            y = shape_attributes['y']\n",
    "            w = shape_attributes['width']\n",
    "            h = shape_attributes['height']\n",
    "            # calculate the annotation coordinates for the text file\n",
    "            yolo_x = (x + (w / 2)) / PIXELS_X\n",
    "            yolo_y = (y + (h / 2)) / PIXELS_Y\n",
    "            yolo_w = w / PIXELS_X\n",
    "            yolo_h = h / PIXELS_Y\n",
    "            # keep record of the small objects\n",
    "            if (yolo_w <= SMALL_OBJECT_W) and (yolo_h <= SMALL_OBJECT_H):\n",
    "                small_objects += 1\n",
    "            # determine the class of this annotation\n",
    "            region_attributes = region['region_attributes']\n",
    "            feature_class = int(''.join(c for c in region_attributes['charge'] if c in digits)) - 1\n",
    "            if feature_class in classes_d.keys():\n",
    "                classes_d[feature_class] += 1\n",
    "            else:\n",
    "                classes_d[feature_class] = 1\n",
    "            # add it to the list\n",
    "            feature_coordinates.append((\"{} {:.6f} {:.6f} {:.6f} {:.6f}\".format(feature_class, yolo_x, yolo_y, yolo_w, yolo_h)))\n",
    "            # draw the overlay\n",
    "            draw.rectangle(xy=[(x, y), (x+w, y+h)], fill=None, outline='red')\n",
    "\n",
    "        # save the overlay tile\n",
    "        tile.save(overlay_filename)\n",
    "        \n",
    "        # write the annotations text file\n",
    "        with open(annotations_path, 'w') as f:\n",
    "            for item in feature_coordinates:\n",
    "                f.write(\"%s\\n\" % item)\n",
    "print(\"{} out of {} objects are small.\".format(small_objects, total_objects))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 1202, 2: 49, 0: 3}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes_d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "assign the tiles to the training sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_proportion = 0.8\n",
    "val_proportion = 0.1\n",
    "train_n = round(len(tile_list) * train_proportion)\n",
    "val_n = round(len(tile_list) * val_proportion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = random.sample(tile_list, train_n)\n",
    "val_test_set = list(set(tile_list) - set(train_set))\n",
    "val_set = random.sample(val_test_set, val_n)\n",
    "test_set = list(set(val_test_set) - set(val_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62, 8, 8)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set), len(val_set), len(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "SETS_BASE_DIR = '{}/sets'.format(TRAINING_SET_BASE_DIR)\n",
    "TRAIN_SET_DIR = '{}/train'.format(SETS_BASE_DIR)\n",
    "VAL_SET_DIR = '{}/validation'.format(SETS_BASE_DIR)\n",
    "TEST_SET_DIR = '{}/test'.format(SETS_BASE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(TRAIN_SET_DIR):\n",
    "    shutil.rmtree(TRAIN_SET_DIR)\n",
    "os.makedirs(TRAIN_SET_DIR)\n",
    "\n",
    "if os.path.exists(VAL_SET_DIR):\n",
    "    shutil.rmtree(VAL_SET_DIR)\n",
    "os.makedirs(VAL_SET_DIR)\n",
    "\n",
    "if os.path.exists(TEST_SET_DIR):\n",
    "    shutil.rmtree(TEST_SET_DIR)\n",
    "os.makedirs(TEST_SET_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_pair in train_set:\n",
    "    shutil.copyfile('{}/{}'.format(PRE_ASSIGNED_FILES_DIR, file_pair[0]), '{}/{}'.format(TRAIN_SET_DIR, file_pair[0]))\n",
    "    shutil.copyfile('{}/{}'.format(PRE_ASSIGNED_FILES_DIR, file_pair[1]), '{}/{}'.format(TRAIN_SET_DIR, file_pair[1]))\n",
    "\n",
    "for file_pair in val_set:\n",
    "    shutil.copyfile('{}/{}'.format(PRE_ASSIGNED_FILES_DIR, file_pair[0]), '{}/{}'.format(VAL_SET_DIR, file_pair[0]))\n",
    "    shutil.copyfile('{}/{}'.format(PRE_ASSIGNED_FILES_DIR, file_pair[1]), '{}/{}'.format(VAL_SET_DIR, file_pair[1]))\n",
    "    \n",
    "for file_pair in test_set:\n",
    "    shutil.copyfile('{}/{}'.format(PRE_ASSIGNED_FILES_DIR, file_pair[0]), '{}/{}'.format(TEST_SET_DIR, file_pair[0]))\n",
    "    shutil.copyfile('{}/{}'.format(PRE_ASSIGNED_FILES_DIR, file_pair[1]), '{}/{}'.format(TEST_SET_DIR, file_pair[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create obj.names, for copying to ./darknet/data, with the object names, each one on a new line\n",
    "LOCAL_NAMES_FILENAME = \"{}/peptides-obj.names\".format(TRAINING_SET_BASE_DIR)\n",
    "NUMBER_OF_CLASSES = 4\n",
    "\n",
    "with open(LOCAL_NAMES_FILENAME, 'w') as f:\n",
    "    for charge in range(1,NUMBER_OF_CLASSES+1):\n",
    "        f.write(\"charge-{}\\n\".format(charge))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create obj.data, for copying to ./darknet/data\n",
    "LOCAL_DATA_FILENAME = \"{}/peptides-obj.data\".format(TRAINING_SET_BASE_DIR)\n",
    "\n",
    "with open(LOCAL_DATA_FILENAME, 'w') as f:\n",
    "    f.write(\"classes={}\\n\".format(NUMBER_OF_CLASSES))\n",
    "    f.write(\"train=data/peptides/train.txt\\n\")\n",
    "    f.write(\"valid=data/peptides/validation.txt\\n\")\n",
    "    f.write(\"names=data/peptides/peptides-obj.names\\n\")\n",
    "    f.write(\"backup=backup/\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the file list for each set\n",
    "with open('{}/train.txt'.format(TRAINING_SET_BASE_DIR), 'w') as f:\n",
    "    for file_pair in train_set:\n",
    "        f.write('data/peptides/sets/train/{}\\n'.format(file_pair[0]))\n",
    "\n",
    "with open('{}/validation.txt'.format(TRAINING_SET_BASE_DIR), 'w') as f:\n",
    "    for file_pair in val_set:\n",
    "        f.write('data/peptides/sets/validation/{}\\n'.format(file_pair[0]))\n",
    "\n",
    "with open('{}/test.txt'.format(TRAINING_SET_BASE_DIR), 'w') as f:\n",
    "    for file_pair in test_set:\n",
    "        f.write('data/peptides/sets/test/{}\\n'.format(file_pair[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a copy of the training set because we'll be augmenting it later\n",
    "backup_training_set_dir = \"{}-backup\".format(TRAIN_SET_DIR)\n",
    "if os.path.exists(backup_training_set_dir):\n",
    "    shutil.rmtree(backup_training_set_dir)\n",
    "shutil.copytree(training_set_dir, backup_training_set_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
