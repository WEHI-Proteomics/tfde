{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import colors, cm, pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "RT_LIMIT_LOWER = 4340\n",
    "RT_LIMIT_UPPER = 4580"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "MS1_CE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASE_NAME = \"/home/daryl/HeLa_20KInt-rt-{}-{}\".format(RT_LIMIT_LOWER,RT_LIMIT_UPPER)\n",
    "BASE_NAME = \"/Users/darylwilding-mcbride/Downloads/HeLa_20KInt-rt-{}-{}\".format(RT_LIMIT_LOWER,RT_LIMIT_UPPER)\n",
    "CONVERTED_DATABASE_NAME = '{}/HeLa_20KInt.sqlite'.format(BASE_NAME)\n",
    "# ALLPEPTIDES_FILENAME = '/home/daryl/maxquant_results/txt/allPeptides.txt'\n",
    "ALLPEPTIDES_FILENAME = '/Users/darylwilding-mcbride/Downloads/maxquant_results/txt/allPeptides.txt'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/darylwilding-mcbride/Downloads/HeLa_20KInt-rt-4340-4580/HeLa_20KInt.sqlite'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONVERTED_DATABASE_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_conn = sqlite3.connect(CONVERTED_DATABASE_NAME)\n",
    "ms1_frame_properties_df = pd.read_sql_query(\"select frame_id,retention_time_secs from frame_properties where retention_time_secs >= {} and retention_time_secs <= {} and collision_energy == {} order by frame_id\".format(RT_LIMIT_LOWER,RT_LIMIT_UPPER,MS1_CE), db_conn)\n",
    "db_conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frame_id</th>\n",
       "      <th>retention_time_secs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40411</td>\n",
       "      <td>4340.340330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40422</td>\n",
       "      <td>4341.521415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40433</td>\n",
       "      <td>4342.702923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40444</td>\n",
       "      <td>4343.883324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40455</td>\n",
       "      <td>4345.067491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   frame_id  retention_time_secs\n",
       "0     40411          4340.340330\n",
       "1     40422          4341.521415\n",
       "2     40433          4342.702923\n",
       "3     40444          4343.883324\n",
       "4     40455          4345.067491"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ms1_frame_properties_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1810854877303427"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame_delay = ms1_frame_properties_df.iloc[1].retention_time_secs - ms1_frame_properties_df.iloc[0].retention_time_secs\n",
    "frame_delay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "203"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ms1_frame_properties_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "MZ_MIN = 100.0\n",
    "MZ_MAX = 1700.0\n",
    "MZ_BIN_WIDTH = 0.1\n",
    "SCAN_MIN = 1\n",
    "SCAN_MAX = 910"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mz_bins = np.arange(start=MZ_MIN, stop=MZ_MAX+MZ_BIN_WIDTH, step=MZ_BIN_WIDTH)  # go slightly wider to accomodate the maximum value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 100. ,  100.1,  100.2, ..., 1699.8, 1699.9, 1700. ])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mz_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16001"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MZ_BIN_COUNT = len(mz_bins)\n",
    "MZ_BIN_COUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "DELTA_MZ = 1.003355     # Mass difference between Carbon-12 and Carbon-13 isotopes, in Da. For calculating the spacing between isotopic peaks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "MZ_TOLERANCE_PPM = 5\n",
    "MZ_TOLERANCE_PERCENT = MZ_TOLERANCE_PPM * 10**-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process the allpeptides file to get the MQ features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_ISOTOPE_CORRELATION = 0.9\n",
    "RT_EACH_SIDE = 0.8\n",
    "\n",
    "allpeptides_df = pd.read_csv(ALLPEPTIDES_FILENAME, sep='\\t')\n",
    "allpeptides_df.rename(columns={'Number of isotopic peaks':'isotope_count', 'm/z':'mz', 'Number of data points':'number_data_points', 'Intensity':'intensity', 'Ion mobility index':'scan', 'Ion mobility index length':'scan_length', 'Ion mobility index length (FWHM)':'scan_length_fwhm', 'Retention time':'rt', 'Retention length':'rt_length', 'Retention length (FWHM)':'rt_length_fwhm', 'Charge':'charge_state', 'Number of pasef MS/MS':'number_pasef_ms2_ids', 'Isotope correlation':'isotope_correlation'}, inplace=True)\n",
    "allpeptides_df = allpeptides_df[allpeptides_df.intensity.notnull()].copy()  # remove all the null intensity rows\n",
    "allpeptides_df = allpeptides_df[allpeptides_df.intensity.notnull() & (allpeptides_df.isotope_correlation >= MIN_ISOTOPE_CORRELATION) & (allpeptides_df.rt >= RT_LIMIT_LOWER) & (allpeptides_df.rt <= RT_LIMIT_UPPER)].copy()\n",
    "\n",
    "allpeptides_df[\"rt_delta\"] = allpeptides_df.rt_length / 2\n",
    "allpeptides_df[\"rt_lower\"] = allpeptides_df.rt - (allpeptides_df.rt_delta * RT_EACH_SIDE)\n",
    "allpeptides_df[\"rt_upper\"] = allpeptides_df.rt + (allpeptides_df.rt_delta * RT_EACH_SIDE)\n",
    "\n",
    "# sort the features by decreasing intensity and give them an ID\n",
    "allpeptides_df.sort_values(by=['intensity'], ascending=False, inplace=True)\n",
    "allpeptides_df[\"mq_feature_id\"] = np.arange(start=1, stop=len(allpeptides_df)+1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11524"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(allpeptides_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "charge states: 1 to 4\n"
     ]
    }
   ],
   "source": [
    "print(\"charge states: {} to {}\".format(allpeptides_df.charge_state.min(), allpeptides_df.charge_state.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the binned rectangle coordinates for all the MQ features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11524"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(allpeptides_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "mz_ppm_tolerance_l = []\n",
    "binned_mz_lower_l = []\n",
    "binned_mz_upper_l = []\n",
    "binned_mz_idx_lower_l = []\n",
    "binned_mz_idx_upper_l = []\n",
    "scan_lower_l = []\n",
    "scan_upper_l = []\n",
    "\n",
    "# calculate the MQ feature rectangles\n",
    "for r in zip(allpeptides_df.mq_feature_id,allpeptides_df.charge_state,allpeptides_df.isotope_count,allpeptides_df.mz,allpeptides_df.scan,allpeptides_df.scan_length):\n",
    "    mq_feature_id = int(r[0])\n",
    "    charge_state = int(r[1])\n",
    "    isotope_count = int(r[2])\n",
    "    mq_feature_mz = r[3]\n",
    "    mq_feature_scan = int(r[4])\n",
    "    mq_feature_scan_length = int(r[5])\n",
    "\n",
    "    expected_isotope_spacing_mz = DELTA_MZ / charge_state\n",
    "\n",
    "    # determine the bounding box coordinates for m/z and scan in real space\n",
    "    mz_ppm_tolerance = mq_feature_mz * MZ_TOLERANCE_PERCENT / 100\n",
    "    mz_ppm_tolerance_l.append((mz_ppm_tolerance))\n",
    "    \n",
    "    # find the bin edges for the feature's mz\n",
    "    binned_mz_idx_lower = int(np.digitize(mq_feature_mz, mz_bins))-1\n",
    "    binned_mz_idx_upper = int(np.digitize(mq_feature_mz + ((isotope_count-1) * expected_isotope_spacing_mz), mz_bins))\n",
    "    rect_mz_lower = mz_bins[binned_mz_idx_lower]\n",
    "    rect_mz_upper = mz_bins[binned_mz_idx_upper]\n",
    "    rect_mz_range = rect_mz_upper - rect_mz_lower\n",
    "    binned_mz_lower_l.append(rect_mz_lower)\n",
    "    binned_mz_upper_l.append(rect_mz_upper)\n",
    "    binned_mz_idx_lower_l.append(binned_mz_idx_lower)\n",
    "    binned_mz_idx_upper_l.append(binned_mz_idx_upper)\n",
    "\n",
    "    rect_scan = mq_feature_scan\n",
    "    rect_scan_delta = mq_feature_scan_length / 2\n",
    "    rect_scan_lower = int(rect_scan - rect_scan_delta)\n",
    "    rect_scan_upper = int(rect_scan + rect_scan_delta)\n",
    "    rect_scan_range = int(mq_feature_scan_length)\n",
    "    scan_lower_l.append(rect_scan_lower)\n",
    "    scan_upper_l.append(rect_scan_upper)\n",
    "    \n",
    "allpeptides_df['mz_ppm_tolerance'] = mz_ppm_tolerance_l\n",
    "allpeptides_df['binned_rect_mz_lower'] = binned_mz_lower_l\n",
    "allpeptides_df['binned_rect_mz_upper'] = binned_mz_upper_l\n",
    "allpeptides_df['binned_rect_mz_idx_lower'] = binned_mz_idx_lower_l\n",
    "allpeptides_df['binned_rect_mz_idx_upper'] = binned_mz_idx_upper_l\n",
    "allpeptides_df['scan_lower'] = scan_lower_l\n",
    "allpeptides_df['scan_upper'] = scan_upper_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIXELS_PER_MZ_BIN = 5\n",
    "PIXELS_PER_SCAN = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# will stretch the image to these dimensions\n",
    "TILE_HEIGHT = SCAN_MAX\n",
    "TILE_WIDTH = TILE_HEIGHT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIXELS_X = MZ_BIN_COUNT * PIXELS_PER_MZ_BIN\n",
    "PIXELS_Y = SCAN_MAX * PIXELS_PER_SCAN\n",
    "MZ_BINS_PER_TILE = int(TILE_WIDTH / PIXELS_PER_MZ_BIN)\n",
    "TILES_PER_FRAME = int(MZ_BIN_COUNT / MZ_BINS_PER_TILE)\n",
    "RESIZE_FACTOR_X = TILE_WIDTH / MZ_BINS_PER_TILE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RESIZE_FACTOR_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "182"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MZ_BINS_PER_TILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TILES_PER_FRAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate tiles for all frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "TILE_BASE = '/Users/darylwilding-mcbride/Downloads/yolo-train'\n",
    "# TILE_BASE = '/home/daryl/yolo-train'\n",
    "PRE_ASSIGNED_FILES_DIR = '{}/pre-assigned'.format(TILE_BASE)\n",
    "OVERLAY_FILES_DIR = '{}/overlay'.format(TILE_BASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "\n",
    "# initialise the directories required for the data set creation\n",
    "if os.path.exists(TILE_BASE):\n",
    "    shutil.rmtree(TILE_BASE)\n",
    "os.makedirs(TILE_BASE)\n",
    "\n",
    "if os.path.exists(PRE_ASSIGNED_FILES_DIR):\n",
    "    shutil.rmtree(PRE_ASSIGNED_FILES_DIR)\n",
    "os.makedirs(PRE_ASSIGNED_FILES_DIR)\n",
    "\n",
    "if os.path.exists(OVERLAY_FILES_DIR):\n",
    "    shutil.rmtree(OVERLAY_FILES_DIR)\n",
    "os.makedirs(OVERLAY_FILES_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the colour to represent the intensity\n",
    "a = np.arange(start=0, stop=200, step=2, dtype=np.int)  # use up the darker colours for the low intensity points\n",
    "b = np.arange(start=200, stop=13000, step=200, dtype=np.int)\n",
    "bounds = np.concatenate([a,b])\n",
    "colour_map = cm.get_cmap(name='magma', lut=len(bounds))\n",
    "norm = colors.BoundaryNorm(boundaries=bounds, ncolors=colour_map.N, clip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFont\n",
    "\n",
    "# load the font to use for labelling the overlays\n",
    "feature_label = ImageFont.truetype('/Library/Fonts/Arial.ttf', 10)\n",
    "# feature_label = ImageFont.truetype('/usr/share/fonts/truetype/liberation/LiberationSans-Regular.ttf', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_CHARGE_STATE = int(allpeptides_df.charge_state.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image, ImageFont, ImageDraw, ImageEnhance\n",
    "\n",
    "# count the instances by class\n",
    "instances_df = pd.DataFrame([(x,0) for x in range(1,MAX_CHARGE_STATE+1)], columns=['charge','instances'])\n",
    "\n",
    "for frame_r in zip(ms1_frame_properties_df.frame_id, ms1_frame_properties_df.retention_time_secs):\n",
    "# for frame_r in zip(ms1_frame_properties_df.iloc[:1].frame_id, ms1_frame_properties_df.iloc[:1].retention_time_secs):\n",
    "    frame_id = int(frame_r[0])\n",
    "    frame_rt = frame_r[1]\n",
    "    \n",
    "    # get the features overlapping this frame\n",
    "    allpeptides_frame_overlap_df = allpeptides_df[(allpeptides_df.rt_lower <= frame_rt) & (allpeptides_df.rt_upper >= frame_rt)].copy()\n",
    "\n",
    "    # load the raw frame points\n",
    "    db_conn = sqlite3.connect(CONVERTED_DATABASE_NAME)\n",
    "    raw_points_df = pd.read_sql_query(\"select mz,scan,intensity from frames where frame_id == {}\".format(frame_id), db_conn)\n",
    "    db_conn.close()\n",
    "    \n",
    "    # convert the raw points to an intensity array\n",
    "    frame_intensity_array = np.zeros([SCAN_MAX+1, MZ_BIN_COUNT+1], dtype=np.uint16)  # scratchpad for the intensity value prior to image conversion\n",
    "    for r in zip(raw_points_df.mz,raw_points_df.scan,raw_points_df.intensity):\n",
    "        mz = r[0]\n",
    "        scan = int(r[1])\n",
    "        if (mz >= MZ_MIN) and (mz <= MZ_MAX) and (scan >= SCAN_MIN) and (scan <= SCAN_MAX):\n",
    "            mz_array_idx = int(np.digitize(mz, mz_bins))-1\n",
    "            scan_array_idx = scan\n",
    "            intensity = int(r[2])\n",
    "            frame_intensity_array[scan_array_idx,mz_array_idx] += intensity\n",
    "\n",
    "    # convert the intensity array to a dataframe\n",
    "    intensity_df = pd.DataFrame(frame_intensity_array).stack().rename_axis(['y', 'x']).reset_index(name='intensity')\n",
    "    # remove all the zero-intensity elements\n",
    "    intensity_df = intensity_df[intensity_df.intensity > 0]\n",
    "    # calculate the colour to represent the intensity\n",
    "    colour_l = []\n",
    "    for r in zip(intensity_df.intensity):\n",
    "        colour_l.append((colour_map(norm(r[0]), bytes=True)[:3]))\n",
    "    intensity_df['colour'] = colour_l\n",
    "\n",
    "    # create an image of the whole frame\n",
    "    frame_im_array = np.zeros([TILE_HEIGHT+1, MZ_BIN_COUNT+1, 3], dtype=np.uint8)  # container for the image\n",
    "    for r in zip(intensity_df.x, intensity_df.y, intensity_df.colour):\n",
    "        x = r[0]\n",
    "        y = r[1]\n",
    "        c = r[2]\n",
    "        frame_im_array[y,x,:] = c\n",
    "\n",
    "    # write out the image tiles for the frame\n",
    "    for tile_idx in range(TILES_PER_FRAME):\n",
    "        # tile m/z coordinates\n",
    "        tile_base_mz = mz_bins[tile_idx * MZ_BINS_PER_TILE]\n",
    "        tile_width_mz = MZ_BINS_PER_TILE * MZ_BIN_WIDTH\n",
    "        # tile index coordinates\n",
    "        tile_idx_base = int(tile_idx * MZ_BINS_PER_TILE)\n",
    "        tile_idx_width = MZ_BINS_PER_TILE\n",
    "        # extract the subset of the frame for this image\n",
    "        tile_im_array = frame_im_array[:,tile_idx_base:tile_idx_base+tile_idx_width,:]\n",
    "        tile = Image.fromarray(tile_im_array, 'RGB')\n",
    "        tile_with_overlay = Image.fromarray(tile_im_array, 'RGB')\n",
    "\n",
    "        # stretch the image to be square\n",
    "        stretched_tile = tile.resize((TILE_WIDTH, TILE_HEIGHT))\n",
    "        stretched_tile_with_overlay = tile_with_overlay.resize((TILE_WIDTH, TILE_HEIGHT))\n",
    "\n",
    "        # get the MQ features that fully fit in the tile\n",
    "        feature_coordinates = []\n",
    "        ap_df = allpeptides_frame_overlap_df\n",
    "        for feature_r in zip(ap_df.mq_feature_id, ap_df.mz, ap_df.charge_state, ap_df.isotope_count, ap_df.binned_rect_mz_idx_lower, ap_df.binned_rect_mz_idx_upper, ap_df.scan_lower, ap_df.scan_upper):\n",
    "            mq_feature_id = int(feature_r[0])\n",
    "            mq_feature_mz = feature_r[1]\n",
    "            mq_feature_charge_state = int(feature_r[2])\n",
    "            isotope_count = int(feature_r[3])\n",
    "            binned_rect_mz_idx_lower = int(feature_r[4]) - 1  # go a bit wider in m/z to make sure we get the whole width\n",
    "            binned_rect_mz_idx_upper = int(feature_r[5]) + 1\n",
    "            scan_lower = int(feature_r[6]) - 2  # and a bit wider in mobility for a bigger margin\n",
    "            scan_upper = int(feature_r[7]) + 2\n",
    "\n",
    "            # draw the MQ features overlay\n",
    "            draw = ImageDraw.Draw(stretched_tile_with_overlay)\n",
    "            x0 = (binned_rect_mz_idx_lower - tile_idx_base) * RESIZE_FACTOR_X\n",
    "            x1 = (binned_rect_mz_idx_upper - tile_idx_base) * RESIZE_FACTOR_X\n",
    "            y0 = scan_lower\n",
    "            y1 = scan_upper\n",
    "            # text file coordinates\n",
    "            x = (x0 + ((x1 - x0) / 2)) / TILE_WIDTH  # YOLO expects x,y to be the centre point of the object\n",
    "            y = (y0 + ((y1 - y0) / 2)) / TILE_HEIGHT\n",
    "            width = (x1 - x0) / TILE_WIDTH\n",
    "            height = (y1 - y0) / TILE_HEIGHT\n",
    "            object_class = mq_feature_charge_state-1\n",
    "            # draw the MQ feature if its centre is within the tile\n",
    "            if ((x >= 0) and (x <= 1) and (y >= 0) and (y <= 1)):\n",
    "                draw.rectangle(xy=[(x0, y0), (x1, y1)], fill=None, outline='red')\n",
    "                draw.text((x0, y0-12), \"{}, +{}, {} iso\".format(mq_feature_id,mq_feature_charge_state,isotope_count), font=feature_label, fill='red')\n",
    "                feature_coordinates.append((\"{} {:.6f} {:.6f} {:.6f} {:.6f}\".format(object_class, x, y, width, height)))\n",
    "                instances_df.loc[(instances_df.charge == mq_feature_charge_state),'instances'] += 1\n",
    "\n",
    "        # write them out\n",
    "        train_filename = '{}/frame-{}-tile-{}-mz-{}-{}.png'.format(PRE_ASSIGNED_FILES_DIR, frame_id, tile_idx, int(tile_base_mz), int(tile_base_mz+tile_width_mz))\n",
    "        train_text_filename = '{}/frame-{}-tile-{}-mz-{}-{}.txt'.format(PRE_ASSIGNED_FILES_DIR, frame_id, tile_idx, int(tile_base_mz), int(tile_base_mz+tile_width_mz))\n",
    "        overlay_filename = '{}/frame-{}-tile-{}-mz-{}-{}.png'.format(OVERLAY_FILES_DIR, frame_id, tile_idx, int(tile_base_mz), int(tile_base_mz+tile_width_mz))\n",
    "        stretched_tile.save(train_filename)\n",
    "        stretched_tile_with_overlay.save(overlay_filename)\n",
    "        # write the text file\n",
    "        with open(train_text_filename, 'w') as f:\n",
    "            for item in feature_coordinates:\n",
    "                f.write(\"%s\\n\" % item)\n",
    "\n",
    "print(\"{}\".format(instances_df))\n",
    "print(\"total number of labelled instances: {}\".format(instances_df.instances.sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the tiles into training, test, validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the file names into a dataframe\n",
    "import glob, os\n",
    "\n",
    "filenames = []\n",
    "for file in sorted(glob.glob(\"{}/*.png\".format(PRE_ASSIGNED_FILES_DIR))):\n",
    "    filenames.append((os.path.basename(os.path.splitext(file)[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_df = pd.DataFrame(filenames, columns=['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>frame-40411-tile-0-mz-100-118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>frame-40411-tile-1-mz-118-136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>frame-40411-tile-10-mz-281-300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>frame-40411-tile-11-mz-300-318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>frame-40411-tile-12-mz-318-336</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             name\n",
       "0   frame-40411-tile-0-mz-100-118\n",
       "1   frame-40411-tile-1-mz-118-136\n",
       "2  frame-40411-tile-10-mz-281-300\n",
       "3  frame-40411-tile-11-mz-300-318\n",
       "4  frame-40411-tile-12-mz-318-336"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allocate the training, validation, and test sets from separate periods of RT, as frames are a time series\n",
    "def train_validate_test_split_v3(df, train_percent=0.8, validate_percent=0.1, seed=None):\n",
    "    test_percent = 1.0 - (train_percent + validate_percent)\n",
    "\n",
    "    # split the ms1 frame ids into three sections according to their proportions\n",
    "    train_ids_df, valid_ids_df, test_ids_df = np.split(ms1_frame_properties_df, [int(train_percent*len(ms1_frame_properties_df)), int((train_percent+validate_percent)*len(ms1_frame_properties_df))])\n",
    "    print(\"training set: {:.1f} to {:.1f} secs ({} frames)\".format(train_ids_df.retention_time_secs.min(), train_ids_df.retention_time_secs.max(), len(train_ids_df)))\n",
    "    print(\"validation set: {:.1f} to {:.1f} secs ({} frames)\".format(valid_ids_df.retention_time_secs.min(), valid_ids_df.retention_time_secs.max(), len(valid_ids_df)))\n",
    "    print(\"test set: {:.1f} to {:.1f} secs ({} frames)\".format(test_ids_df.retention_time_secs.min(), test_ids_df.retention_time_secs.max(), len(test_ids_df)))\n",
    "    \n",
    "    train_terms = ['frame-' + str(s) for s in train_ids_df.frame_id]\n",
    "    train_df = df[df['name'].str.contains('|'.join(train_terms))].copy()\n",
    "\n",
    "    valid_terms = ['frame-' + str(s) for s in valid_ids_df.frame_id]\n",
    "    valid_df = df[df['name'].str.contains('|'.join(valid_terms))].copy()\n",
    "\n",
    "    test_terms = ['frame-' + str(s) for s in test_ids_df.frame_id]\n",
    "    test_df = df[df['name'].str.contains('|'.join(test_terms))].copy()\n",
    "\n",
    "    return train_df, valid_df, test_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allocate the test set from the last of the tiles in RT, randomly allocated the remainder into training, validation\n",
    "def train_validate_test_split_v2(df, train_percent=0.9, validate_percent=0.05, seed=None):\n",
    "    test_percent = 1.0 - (train_percent + validate_percent)\n",
    "    # take the last test_precent of the frames for the test set\n",
    "    test_set_frame_ids = list(ms1_frame_properties_df.tail(int(len(ms1_frame_properties_df) * test_percent)).frame_id)\n",
    "    terms = ['frame-' + str(s) for s in test_set_frame_ids]\n",
    "    test_df = df[df['name'].str.contains('|'.join(terms))].copy()\n",
    "    # remove the test set from the train/valid set\n",
    "    train_valid_df = df[~df.name.isin(test_df.name)]\n",
    "    # randomly assign tiles to the train and valid sets\n",
    "    np.random.seed(seed)\n",
    "    perm = np.random.permutation(train_valid_df.index)\n",
    "    m = len(df.index)\n",
    "    train_end = int(train_percent * m)\n",
    "    train_df = train_valid_df.loc[perm[:train_end]].copy()\n",
    "    validate_df = train_valid_df.loc[perm[train_end:]].copy()\n",
    "    return train_df, validate_df, test_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set: 4340.3 to 4530.6 secs (162 frames)\n",
      "validation set: 4531.7 to 4554.2 secs (20 frames)\n",
      "test set: 4555.4 to 4579.0 secs (21 frames)\n"
     ]
    }
   ],
   "source": [
    "train_df, validate_df, test_df = train_validate_test_split_v3(fn_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14094, 1740, 1827)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df), len(validate_df), len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [name]\n",
       "Index: []"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df.name.isin(test_df.name)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly assign each tile to a set\n",
    "def train_validate_test_split(df, train_percent=.9, validate_percent=.05, seed=None):\n",
    "    np.random.seed(seed)\n",
    "    perm = np.random.permutation(df.index)\n",
    "    m = len(df.index)\n",
    "    train_end = int(train_percent * m)\n",
    "    validate_end = int(validate_percent * m) + train_end\n",
    "    train = df.loc[perm[:train_end]]\n",
    "    validate = df.loc[perm[train_end:validate_end]]\n",
    "    test = df.loc[perm[validate_end:]]\n",
    "    return train, validate, test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "data_dirs = ['train', 'validation', 'test']\n",
    "data_dfs = [train_df, validate_df, test_df]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "DESTINATION_DATASET_BASE = 'data/peptides'\n",
    "LOCAL_DATA_FILES_DIR = '{}/data-files'.format(TILE_BASE)\n",
    "DESTINATION_DATA_FILES_DIR = '{}/data-files'.format(DESTINATION_DATASET_BASE)\n",
    "FILE_LIST_SUFFIX = 'list'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise the directories required for the data set organisation\n",
    "if os.path.exists(LOCAL_DATA_FILES_DIR):\n",
    "    shutil.rmtree(LOCAL_DATA_FILES_DIR)\n",
    "os.makedirs(LOCAL_DATA_FILES_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train\n",
      "processing validation\n",
      "processing test\n"
     ]
    }
   ],
   "source": [
    "for idx,dd in enumerate(data_dirs):\n",
    "    print(\"processing {}\".format(dd))\n",
    "    \n",
    "    # initialise the directory for each set\n",
    "    data_dir = \"{}/{}\".format(TILE_BASE, dd)\n",
    "    if os.path.exists(data_dir):\n",
    "        shutil.rmtree(data_dir)\n",
    "    os.makedirs(data_dir)\n",
    "    \n",
    "    # create the prefix column\n",
    "    data_dfs[idx]['text_entry'] = '{}/{}/'.format(DESTINATION_DATASET_BASE, dd) + data_dfs[idx].name + '.png'\n",
    "\n",
    "    # copy the files into their respective directories\n",
    "    for r in zip(data_dfs[idx].name):\n",
    "        shutil.copyfile(\"{}/{}.png\".format(PRE_ASSIGNED_FILES_DIR,r[0]), \"{}/{}/{}.png\".format(TILE_BASE, dd, r[0]))\n",
    "        shutil.copyfile(\"{}/{}.txt\".format(PRE_ASSIGNED_FILES_DIR,r[0]), \"{}/{}/{}.txt\".format(TILE_BASE, dd, r[0]))\n",
    "\n",
    "    # generate the text files for each set\n",
    "    data_dfs[idx].text_entry.to_csv(\"{}/{}-{}.txt\".format(LOCAL_DATA_FILES_DIR, dd, FILE_LIST_SUFFIX), index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished writing /Users/darylwilding-mcbride/Downloads/yolo-train/peptides-obj.names\n",
      "finished writing /Users/darylwilding-mcbride/Downloads/yolo-train/peptides-obj.data\n"
     ]
    }
   ],
   "source": [
    "# create the names and data files for Darknet\n",
    "LOCAL_NAMES_FILENAME = \"{}/peptides-obj.names\".format(TILE_BASE)\n",
    "DESTINATION_NAMES_FILENAME = \"{}/peptides-obj.names\".format(DESTINATION_DATASET_BASE)\n",
    "LOCAL_DATA_FILENAME = \"{}/peptides-obj.data\".format(TILE_BASE)\n",
    "\n",
    "with open(LOCAL_NAMES_FILENAME, 'w') as f:\n",
    "    for charge in range(1,MAX_CHARGE_STATE+1):\n",
    "        f.write(\"charge-{}\\n\".format(charge))\n",
    "\n",
    "print(\"finished writing {}\".format(LOCAL_NAMES_FILENAME))\n",
    "\n",
    "with open(LOCAL_DATA_FILENAME, 'w') as f:\n",
    "    f.write(\"classes={}\\n\".format(MAX_CHARGE_STATE))\n",
    "    f.write(\"train={}\\n\".format(\"{}/{}-{}.txt\".format(DESTINATION_DATA_FILES_DIR, data_dirs[0], FILE_LIST_SUFFIX)))\n",
    "    f.write(\"valid={}\\n\".format(\"{}/{}-{}.txt\".format(DESTINATION_DATA_FILES_DIR, data_dirs[1], FILE_LIST_SUFFIX)))\n",
    "    f.write(\"names={}\\n\".format(DESTINATION_NAMES_FILENAME))\n",
    "    f.write(\"backup=backup/\\n\")\n",
    "\n",
    "print(\"finished writing {}\".format(LOCAL_DATA_FILENAME))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
