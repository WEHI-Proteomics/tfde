{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2DTranspose, ConvLSTM2D, BatchNormalization, TimeDistributed, Conv2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import LayerNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_DIR = '/Users/darylwilding-mcbride/Downloads/experiments/dwm-test'\n",
    "RUN_NAME = '190719_Hela_Ecoli_1to1_01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENCODED_FEATURES_DIR = '{}/encoded-features/{}'.format(EXPERIMENT_DIR, RUN_NAME)\n",
    "FEATURE_SLICES_DIR = '{}/slices'.format(ENCODED_FEATURES_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the feature IDs that we processed earlier\n",
    "FEATURE_ID_LIST_FILE = '{}/feature_ids.pkl'.format(ENCODED_FEATURES_DIR)\n",
    "feature_list_df = pd.read_pickle(FEATURE_ID_LIST_FILE)\n",
    "features_l = feature_list_df.feature_id.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the feature slices\n",
    "feature_movies_l = []\n",
    "for feature_id in features_l:\n",
    "    # load the slices for the feature\n",
    "    slices_l = sorted(glob.glob(\"{}/feature-{}-slice-*.png\".format(FEATURE_SLICES_DIR, feature_id)))\n",
    "    feature_slices_l = []\n",
    "    for feature_slice in slices_l:\n",
    "        # load the image and generate the feature vector\n",
    "        img = Image.open(feature_slice)\n",
    "        x = image.img_to_array(img.resize((256,256)))\n",
    "        feature_slices_l.append(x)\n",
    "    feature_slices = np.array(feature_slices_l)\n",
    "    feature_slices = feature_slices.astype('float32') / 255.\n",
    "    feature_movies_l.append(feature_slices)\n",
    "feature_movies = np.array(feature_movies_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_movies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model\n",
    "seq = Sequential()\n",
    "\n",
    "seq.add(TimeDistributed(Conv2D(128, (11, 11), strides=4, padding=\"same\"), batch_input_shape=(None, 20, 256, 256, 3)))  # 20 images of 256x256x3\n",
    "seq.add(LayerNormalization())\n",
    "\n",
    "seq.add(TimeDistributed(Conv2D(64, (5, 5), strides=2, padding=\"same\")))\n",
    "seq.add(LayerNormalization())\n",
    "# # # # #\n",
    "seq.add(ConvLSTM2D(64, (3, 3), padding=\"same\", return_sequences=True))\n",
    "seq.add(LayerNormalization())\n",
    "\n",
    "seq.add(ConvLSTM2D(32, (3, 3), padding=\"same\", return_sequences=True))\n",
    "seq.add(LayerNormalization())\n",
    "\n",
    "seq.add(ConvLSTM2D(64, (3, 3), padding=\"same\", return_sequences=True))\n",
    "seq.add(LayerNormalization(name='encoded'))\n",
    "\n",
    "# # # # #\n",
    "seq.add(TimeDistributed(Conv2DTranspose(64, (5, 5), strides=2, padding=\"same\")))\n",
    "seq.add(LayerNormalization())\n",
    "\n",
    "seq.add(TimeDistributed(Conv2DTranspose(128, (11, 11), strides=4, padding=\"same\")))\n",
    "seq.add(LayerNormalization())\n",
    "\n",
    "seq.add(TimeDistributed(Conv2D(3, (11, 11), activation=\"sigmoid\", padding=\"same\")))\n",
    "print(seq.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Model(inputs=seq.inputs, outputs=seq.get_layer(name='encoded').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq.compile(loss='mse', optimizer=Adam(lr=1e-4, decay=1e-5, epsilon=1e-6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq.fit(feature_movies, feature_movies, batch_size=5, epochs=20, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq.save('{}/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
