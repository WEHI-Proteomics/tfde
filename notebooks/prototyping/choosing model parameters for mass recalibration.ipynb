{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import glob\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV,ShuffleSplit\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model train/test set preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_base_dir = '/media/big-ssd/experiments'\n",
    "experiment_name = 'P3856'\n",
    "feature_detection_method = 'pasef'\n",
    "run_name = 'P3856_YHE211_1_Slot1-1_1_5104'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_DIR = \"{}/{}\".format(experiment_base_dir, experiment_name)\n",
    "IDENTIFICATIONS_DIR = '{}/identifications-{}'.format(EXPERIMENT_DIR, feature_detection_method)\n",
    "IDENTIFICATIONS_FILE = '{}/exp-{}-identifications-{}.pkl'.format(IDENTIFICATIONS_DIR, experiment_name, feature_detection_method)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAXIMUM_Q_VALUE_FOR_RECAL_TRAINING_SET = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 14235 identifications with q-value lower than 0.1 from /media/big-ssd/experiments/P3856/identifications-pasef/exp-P3856-identifications-pasef.pkl\n",
      "loaded 65370 features from 1 files for recalibration\n"
     ]
    }
   ],
   "source": [
    "# load the identifications to use for the training set\n",
    "with open(IDENTIFICATIONS_FILE, 'rb') as handle:\n",
    "    idents_df = pickle.load(handle)['identifications_df']\n",
    "idents_df = idents_df[(idents_df['percolator q-value'] <= MAXIMUM_Q_VALUE_FOR_RECAL_TRAINING_SET)]\n",
    "idents_df = idents_df[(idents_df.run_name == run_name)]\n",
    "print('loaded {} identifications with q-value lower than {} from {}'.format(len(idents_df), MAXIMUM_Q_VALUE_FOR_RECAL_TRAINING_SET, IDENTIFICATIONS_FILE))\n",
    "\n",
    "# load the features for recalibration\n",
    "FEATURES_DIR = '{}/features-{}'.format(EXPERIMENT_DIR, feature_detection_method)\n",
    "feature_files = glob.glob(\"{}/exp-{}-run-*-features-{}-dedup.pkl\".format(FEATURES_DIR, experiment_name, feature_detection_method))\n",
    "features_l = []\n",
    "for f in feature_files:\n",
    "    with open(f, 'rb') as handle:\n",
    "        features_l.append(pickle.load(handle)['features_df'])\n",
    "features_df = pd.concat(features_l, axis=0, sort=False)\n",
    "features_df = features_df[(features_df.run_name == run_name)]\n",
    "print('loaded {} features from {} files for recalibration'.format(len(features_df), len(feature_files)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = idents_df[['mono_mz_without_saturated_points','scan_apex','rt_apex','feature_intensity']].to_numpy()\n",
    "y = idents_df[['mass_error']].to_numpy()[:,0]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idents_df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12811, 1424)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test1 = {'n_estimators':range(20,81,10)}\n",
    "gsearch1 = GridSearchCV(estimator=GradientBoostingRegressor(learning_rate=0.05, \n",
    "                                                              min_samples_split=500,\n",
    "                                                              min_samples_leaf=50,\n",
    "                                                              max_depth=8,\n",
    "                                                              max_features='sqrt',\n",
    "                                                              subsample=0.8,\n",
    "                                                              random_state=10), \n",
    "param_grid = param_test1, scoring='neg_mean_absolute_error', n_jobs=-1, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=GradientBoostingRegressor(learning_rate=0.05,\n",
       "                                                 max_depth=8,\n",
       "                                                 max_features='sqrt',\n",
       "                                                 min_samples_leaf=50,\n",
       "                                                 min_samples_split=500,\n",
       "                                                 random_state=10,\n",
       "                                                 subsample=0.8),\n",
       "             n_jobs=-1, param_grid={'n_estimators': range(20, 81, 10)},\n",
       "             scoring='neg_mean_absolute_error')"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.295492</td>\n",
       "      <td>0.002927</td>\n",
       "      <td>0.002451</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>20</td>\n",
       "      <td>{'n_estimators': 20}</td>\n",
       "      <td>-0.004521</td>\n",
       "      <td>-0.004683</td>\n",
       "      <td>-0.004872</td>\n",
       "      <td>-0.004688</td>\n",
       "      <td>-0.004680</td>\n",
       "      <td>-0.004689</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.438993</td>\n",
       "      <td>0.003189</td>\n",
       "      <td>0.003305</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>30</td>\n",
       "      <td>{'n_estimators': 30}</td>\n",
       "      <td>-0.004478</td>\n",
       "      <td>-0.004627</td>\n",
       "      <td>-0.004830</td>\n",
       "      <td>-0.004648</td>\n",
       "      <td>-0.004648</td>\n",
       "      <td>-0.004646</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.582859</td>\n",
       "      <td>0.007512</td>\n",
       "      <td>0.004133</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>40</td>\n",
       "      <td>{'n_estimators': 40}</td>\n",
       "      <td>-0.004451</td>\n",
       "      <td>-0.004604</td>\n",
       "      <td>-0.004816</td>\n",
       "      <td>-0.004628</td>\n",
       "      <td>-0.004639</td>\n",
       "      <td>-0.004628</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.730795</td>\n",
       "      <td>0.004411</td>\n",
       "      <td>0.004854</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>50</td>\n",
       "      <td>{'n_estimators': 50}</td>\n",
       "      <td>-0.004444</td>\n",
       "      <td>-0.004592</td>\n",
       "      <td>-0.004811</td>\n",
       "      <td>-0.004619</td>\n",
       "      <td>-0.004628</td>\n",
       "      <td>-0.004619</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.882536</td>\n",
       "      <td>0.003551</td>\n",
       "      <td>0.005578</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>60</td>\n",
       "      <td>{'n_estimators': 60}</td>\n",
       "      <td>-0.004443</td>\n",
       "      <td>-0.004587</td>\n",
       "      <td>-0.004809</td>\n",
       "      <td>-0.004614</td>\n",
       "      <td>-0.004625</td>\n",
       "      <td>-0.004616</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.025048</td>\n",
       "      <td>0.018444</td>\n",
       "      <td>0.005974</td>\n",
       "      <td>0.000451</td>\n",
       "      <td>70</td>\n",
       "      <td>{'n_estimators': 70}</td>\n",
       "      <td>-0.004440</td>\n",
       "      <td>-0.004579</td>\n",
       "      <td>-0.004805</td>\n",
       "      <td>-0.004615</td>\n",
       "      <td>-0.004622</td>\n",
       "      <td>-0.004612</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.964760</td>\n",
       "      <td>0.090736</td>\n",
       "      <td>0.005568</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>80</td>\n",
       "      <td>{'n_estimators': 80}</td>\n",
       "      <td>-0.004444</td>\n",
       "      <td>-0.004577</td>\n",
       "      <td>-0.004806</td>\n",
       "      <td>-0.004613</td>\n",
       "      <td>-0.004620</td>\n",
       "      <td>-0.004612</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.295492      0.002927         0.002451        0.000023   \n",
       "1       0.438993      0.003189         0.003305        0.000058   \n",
       "2       0.582859      0.007512         0.004133        0.000080   \n",
       "3       0.730795      0.004411         0.004854        0.000061   \n",
       "4       0.882536      0.003551         0.005578        0.000062   \n",
       "5       1.025048      0.018444         0.005974        0.000451   \n",
       "6       0.964760      0.090736         0.005568        0.000047   \n",
       "\n",
       "  param_n_estimators                params  split0_test_score  \\\n",
       "0                 20  {'n_estimators': 20}          -0.004521   \n",
       "1                 30  {'n_estimators': 30}          -0.004478   \n",
       "2                 40  {'n_estimators': 40}          -0.004451   \n",
       "3                 50  {'n_estimators': 50}          -0.004444   \n",
       "4                 60  {'n_estimators': 60}          -0.004443   \n",
       "5                 70  {'n_estimators': 70}          -0.004440   \n",
       "6                 80  {'n_estimators': 80}          -0.004444   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0          -0.004683          -0.004872          -0.004688          -0.004680   \n",
       "1          -0.004627          -0.004830          -0.004648          -0.004648   \n",
       "2          -0.004604          -0.004816          -0.004628          -0.004639   \n",
       "3          -0.004592          -0.004811          -0.004619          -0.004628   \n",
       "4          -0.004587          -0.004809          -0.004614          -0.004625   \n",
       "5          -0.004579          -0.004805          -0.004615          -0.004622   \n",
       "6          -0.004577          -0.004806          -0.004613          -0.004620   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0        -0.004689        0.000111                7  \n",
       "1        -0.004646        0.000112                6  \n",
       "2        -0.004628        0.000116                5  \n",
       "3        -0.004619        0.000117                4  \n",
       "4        -0.004616        0.000117                3  \n",
       "5        -0.004612        0.000117                2  \n",
       "6        -0.004612        0.000116                1  "
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(gsearch1.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'n_estimators': 80}, -0.004611954045469387)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'max_depth': 7, 'min_samples_split': 200}, -0.0045999623225885)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test2 = {'max_depth':range(5,16,2), 'min_samples_split':range(100,1001,100)}\n",
    "gsearch2 = GridSearchCV(estimator=GradientBoostingRegressor(learning_rate=0.05, \n",
    "                                                              min_samples_leaf=50,\n",
    "                                                              max_features='sqrt',\n",
    "                                                              subsample=0.8,\n",
    "                                                              random_state=10,\n",
    "                                                              n_estimators=80), \n",
    "                        param_grid=param_test2, scoring='neg_mean_absolute_error', n_jobs=-1, cv=5)\n",
    "gsearch2.fit(X_train, y_train)\n",
    "gsearch2.best_params_, gsearch2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'min_samples_leaf': 30, 'min_samples_split': 200}, -0.004599189500370496)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test3 = {'min_samples_split':range(100,2100,100), 'min_samples_leaf':range(10,71,10)}\n",
    "gsearch3 = GridSearchCV(estimator=GradientBoostingRegressor(learning_rate=0.05, \n",
    "                                                              max_features='sqrt',\n",
    "                                                              subsample=0.8,\n",
    "                                                              random_state=10,\n",
    "                                                              n_estimators=80,\n",
    "                                                           max_depth=7), \n",
    "                        param_grid=param_test3, scoring='neg_mean_absolute_error', n_jobs=-1, cv=5)\n",
    "gsearch3.fit(X_train, y_train)\n",
    "gsearch3.best_params_, gsearch3.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'max_features': 2}, -0.004599189500370496)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test4 = {'max_features':[1,2,3,4]}\n",
    "gsearch4 = GridSearchCV(estimator=GradientBoostingRegressor(learning_rate=0.05, \n",
    "                                                              subsample=0.8,\n",
    "                                                              random_state=10,\n",
    "                                                              n_estimators=80,\n",
    "                                                           max_depth=7,\n",
    "                                                           min_samples_leaf=30,\n",
    "                                                           min_samples_split=200), \n",
    "                        param_grid=param_test4, scoring='neg_mean_absolute_error', n_jobs=-1, cv=5)\n",
    "gsearch4.fit(X_train, y_train)\n",
    "gsearch4.best_params_, gsearch4.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'subsample': 0.8}, -0.004599189500370496)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test5 = {'subsample':[0.6,0.7,0.75,0.8,0.85,0.9]}\n",
    "gsearch5 = GridSearchCV(estimator=GradientBoostingRegressor(learning_rate=0.05, \n",
    "                                                              random_state=10,\n",
    "                                                              n_estimators=80,\n",
    "                                                           max_depth=7,\n",
    "                                                           min_samples_leaf=30,\n",
    "                                                           min_samples_split=200,\n",
    "                                                           max_features=2), \n",
    "                        param_grid=param_test5, scoring='neg_mean_absolute_error', n_jobs=-1, cv=5)\n",
    "gsearch5.fit(X_train, y_train)\n",
    "gsearch5.best_params_, gsearch5.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'learning_rate': 0.05}, -0.004599189500370496)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test6 = {'learning_rate':[0.01,0.05,0.001,0.005]}\n",
    "gsearch6 = GridSearchCV(estimator=GradientBoostingRegressor(random_state=10,\n",
    "                                                              n_estimators=80,\n",
    "                                                           max_depth=7,\n",
    "                                                           min_samples_leaf=30,\n",
    "                                                           min_samples_split=200,\n",
    "                                                           max_features=2,\n",
    "                                                           subsample=0.8), \n",
    "                        param_grid=param_test6, scoring='neg_mean_absolute_error', n_jobs=-1, cv=5)\n",
    "gsearch6.fit(X_train, y_train)\n",
    "gsearch6.best_params_, gsearch6.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(learning_rate=0.05, max_depth=7, max_features=2,\n",
       "                          min_samples_leaf=30, min_samples_split=200,\n",
       "                          n_estimators=5000, random_state=10, subsample=0.8)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator=GradientBoostingRegressor(learning_rate=0.05,\n",
    "                                random_state=10,\n",
    "                                                              n_estimators=5000,\n",
    "                                                           max_depth=7,\n",
    "                                                           min_samples_leaf=30,\n",
    "                                                           min_samples_split=200,\n",
    "                                                           max_features=2,\n",
    "                                                           subsample=0.8)\n",
    "estimator.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared for Train: 1.00\n",
      "R-squared for Test: -0.33\n"
     ]
    }
   ],
   "source": [
    "print(\"R-squared for Train: %.2f\" %estimator.score(X_train, y_train))\n",
    "print(\"R-squared for Test: %.2f\" %estimator.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### randomised search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"loss\": ['ls','lad','huber'],\n",
    "    \"learning_rate\": [0.01, 0.05, 0.1, 0.2],\n",
    "    'n_estimators': range(20,510,10),\n",
    "    'max_depth':range(5,30,2), \n",
    "    'min_samples_split':range(100,1001,100),\n",
    "    'subsample':list(np.arange(0.2,0.9,0.1)),\n",
    "    'min_samples_leaf':range(10,71,10),\n",
    "    'max_features':[\"log2\", \"sqrt\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr = GradientBoostingRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters {'subsample': 0.8000000000000003, 'n_estimators': 340, 'min_samples_split': 600, 'min_samples_leaf': 50, 'max_features': 'log2', 'max_depth': 11, 'loss': 'lad', 'learning_rate': 0.1}, score -0.004578712097575632\n"
     ]
    }
   ],
   "source": [
    "rsearch = RandomizedSearchCV(gbr, parameters, n_iter=100, n_jobs=-1, random_state=10, cv=5, scoring='neg_mean_absolute_error')\n",
    "rsearch.fit(X_train, y_train)\n",
    "print('best parameters {}, score {}'.format(rsearch.best_params_, rsearch.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared for train: 0.1\n",
      "R-squared for test: 0.06\n"
     ]
    }
   ],
   "source": [
    "print('R-squared for train: {}'.format(round(rsearch.best_estimator_.score(X_train, y_train),2)))\n",
    "print('R-squared for test: {}'.format(round(rsearch.best_estimator_.score(X_test, y_test),2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
