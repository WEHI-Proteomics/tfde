{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from urllib import parse\n",
    "from urllib.request import urlopen\n",
    "from PIL import Image, ImageDraw\n",
    "import os, shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from matplotlib import colors, cm, pyplot as plt\n",
    "from random import randint\n",
    "import glob\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIXELS_X = 910\n",
    "PIXELS_Y = 910  # equal to the number of scan lines\n",
    "PIXELS_PER_BIN = 1\n",
    "MZ_MIN = 100.0\n",
    "MZ_MAX = 1700.0\n",
    "SCAN_MAX = PIXELS_Y\n",
    "SCAN_MIN = 1\n",
    "MZ_PER_TILE = 18.0\n",
    "MZ_BIN_WIDTH = MZ_PER_TILE / (PIXELS_X * PIXELS_PER_BIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mz_bins = np.arange(start=MZ_MIN, stop=MZ_MAX+MZ_BIN_WIDTH, step=MZ_BIN_WIDTH)  # go slightly wider to accommodate the maximum value\n",
    "MZ_BIN_COUNT = len(mz_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_features_to_synthesise_for_charge = {2:10, 3:45}  # charge:number_to_synthesise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = '/Users/darylwilding-mcbride/Documents/Personal/PhD/source/yolo-tile-labelling'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYNTHESISED_TILES_DIR = '{}/synthesised-tiles'.format(BASE_DIR)\n",
    "TRAINING_SET_BASE_DIR = '{}/training set'.format(BASE_DIR)\n",
    "TRAINING_SET_FILES_DIR = '{}/sets/train'.format(TRAINING_SET_BASE_DIR)\n",
    "TRAINING_SET_BACKUP_FILES_DIR = '{}/sets/train-backup'.format(TRAINING_SET_BASE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONVERTED_DATABASE_NAME = '/Users/darylwilding-mcbride/Downloads/experiments/dwm-test/converted-databases/exp-dwm-test-run-190719_Hela_Ecoli_1to1_01-converted.sqlite'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(SYNTHESISED_TILES_DIR):\n",
    "    shutil.rmtree(SYNTHESISED_TILES_DIR)\n",
    "os.makedirs(SYNTHESISED_TILES_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "annotations_file_name = '{}/annotated tiles/via_export_json_aw.json'.format(BASE_DIR)\n",
    "with open(annotations_file_name) as annotations_file:\n",
    "    annotations = json.load(annotations_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tile_coords_to_data_coords(tile_name, tile_width, tile_height, region_x, region_y, region_width, region_height, canvas_scale):\n",
    "    # determine the tile id and frame id from the tile URL\n",
    "    elements = tile_name.split('/')\n",
    "    tile_id = int(elements[4])\n",
    "    frame_id = int(elements[6])\n",
    "\n",
    "    tile_mz_lower = MZ_MIN + (tile_id * MZ_PER_TILE)\n",
    "    tile_mz_upper = tile_mz_lower + MZ_PER_TILE\n",
    "\n",
    "    # scale the tile coordinates by the canvas scale\n",
    "    region_x = region_x * canvas_scale\n",
    "    region_y = region_y * canvas_scale\n",
    "    region_width = region_width * canvas_scale\n",
    "    region_height = region_height * canvas_scale\n",
    "\n",
    "    region_mz_lower = ((region_x / tile_width) * (tile_mz_upper - tile_mz_lower)) + tile_mz_lower\n",
    "    region_mz_upper = (((region_x + region_width) / tile_width) * (tile_mz_upper - tile_mz_lower)) + tile_mz_lower\n",
    "    region_scan_lower = region_y\n",
    "    region_scan_upper = region_y + region_height\n",
    "\n",
    "    d = {}\n",
    "    d['frame_id'] = frame_id\n",
    "    d['mz_lower'] = region_mz_lower\n",
    "    d['mz_upper'] = region_mz_upper\n",
    "    d['scan_lower'] = region_scan_lower\n",
    "    d['scan_upper'] = region_scan_upper\n",
    "    return d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_intensity_offsets(number_of_offsets):\n",
    "    intensity_offsets_l = [-90, -70, -50, -30, +30, +50, +70, +90]\n",
    "    offset_increment = 20\n",
    "    if number_of_offsets <= len(intensity_offsets_l):\n",
    "        result = random.sample(intensity_offsets_l, number_of_offsets)\n",
    "    else:\n",
    "        number_to_add = number_of_offsets - len(intensity_offsets_l)\n",
    "        base_offset = max(intensity_offsets_l)\n",
    "        for n in range(number_to_add):\n",
    "            intensity_offsets_l.append(base_offset + ((n+1) * offset_increment))\n",
    "        result = intensity_offsets_l\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_synthesised_tile(frame_id, tile_idx, feature_idx, raw_points_df, tile_dir_d, feature_coordinates, number_to_synthesise):\n",
    "    frame_intensity_array = np.zeros([SCAN_MAX+1, MZ_BIN_COUNT+1], dtype=np.uint16)  # scratchpad for the intensity value prior to image conversion\n",
    "    for r in zip(raw_points_df.mz,raw_points_df.scan,raw_points_df.intensity):\n",
    "        mz = r[0]\n",
    "        scan = int(r[1])\n",
    "        if (mz >= MZ_MIN) and (mz <= MZ_MAX) and (scan >= SCAN_MIN) and (scan <= SCAN_MAX):\n",
    "            mz_array_idx = int(np.digitize(mz, mz_bins))-1\n",
    "            scan_array_idx = scan\n",
    "            intensity = int(r[2])\n",
    "            frame_intensity_array[scan_array_idx,mz_array_idx] += intensity\n",
    "\n",
    "    # calculate the colour to represent the intensity\n",
    "    colour_map = cm.get_cmap(name='magma')\n",
    "    norm = colors.LogNorm(vmin=1, vmax=5e3, clip=True)  # aiming to get good colour variation in the lower range, and clipping everything else\n",
    "\n",
    "    # convert the intensity array to a dataframe\n",
    "    intensity_df = pd.DataFrame(frame_intensity_array).stack().rename_axis(['y', 'x']).reset_index(name='intensity')\n",
    "    # remove all the zero-intensity elements\n",
    "    intensity_df = intensity_df[intensity_df.intensity > 0]\n",
    "    \n",
    "    intensity_offsets_l = get_intensity_offsets(number_to_synthesise)\n",
    "    for intensity_percent_offset in intensity_offsets_l:\n",
    "        # apply a uniform offset to the intensities\n",
    "        intensity_df['adjusted_intensity'] = intensity_df.intensity + (intensity_df.intensity * intensity_percent_offset / 100.0)\n",
    "\n",
    "        # calculate the colour to represent the intensity\n",
    "        colour_l = []\n",
    "        for r in zip(intensity_df.adjusted_intensity):\n",
    "            colour_l.append((colour_map(norm(r[0]), bytes=True)[:3]))\n",
    "        intensity_df['colour'] = colour_l\n",
    "\n",
    "        # create an image of the whole frame\n",
    "        frame_im_array = np.zeros([PIXELS_Y+1, MZ_BIN_COUNT+1, 3], dtype=np.uint8)  # container for the image\n",
    "        for r in zip(intensity_df.x, intensity_df.y, intensity_df.colour):\n",
    "            x = r[0]\n",
    "            y = r[1]\n",
    "            c = r[2]\n",
    "            frame_im_array[y,x,:] = c\n",
    "\n",
    "        # extract the pixels for the specified tiles\n",
    "        tile_idx_base = tile_idx * PIXELS_X\n",
    "        tile_idx_width = PIXELS_X\n",
    "        \n",
    "        # extract the subset of the frame for this image\n",
    "        tile_im_array = frame_im_array[:,tile_idx_base:tile_idx_base+tile_idx_width,:]\n",
    "        tile = Image.fromarray(tile_im_array, 'RGB')\n",
    "\n",
    "        # write the tile\n",
    "        tile.save('{}/frame-{}-tile-{}-feature-{}-intensity-aug-{}.png'.format(tile_dir_d[tile_idx], frame_id, tile_idx, feature_idx, intensity_percent_offset))\n",
    "        \n",
    "        # write the annotations text file\n",
    "        with open('{}/frame-{}-tile-{}-feature-{}-intensity-aug-{}.txt'.format(tile_dir_d[tile_idx], frame_id, tile_idx, feature_idx, intensity_percent_offset), 'w') as f:\n",
    "            for item in feature_coordinates:\n",
    "                f.write(\"%s\\n\" % item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_idx_list = [33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created /Users/darylwilding-mcbride/Documents/Personal/PhD/source/yolo-tile-labelling/synthesised-tiles/tile-33\n"
     ]
    }
   ],
   "source": [
    "# set up a tile directory for each run\n",
    "tile_dir_d = {}\n",
    "for tile_idx in tile_idx_list:\n",
    "    tile_dir = \"{}/tile-{}\".format(SYNTHESISED_TILES_DIR, tile_idx)\n",
    "    tile_dir_d[tile_idx] = tile_dir\n",
    "    if os.path.exists(tile_dir):\n",
    "        shutil.rmtree(tile_dir)\n",
    "    os.makedirs(tile_dir)\n",
    "    print(\"Created {}\".format(tile_dir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/darylwilding-mcbride/Documents/Personal/PhD/source/yolo-tile-labelling/training set/sets/train'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# restore the backup of the original training set made during the previous step\n",
    "if os.path.exists(TRAINING_SET_FILES_DIR):\n",
    "    shutil.rmtree(TRAINING_SET_FILES_DIR)\n",
    "shutil.copytree(TRAINING_SET_BACKUP_FILES_DIR, TRAINING_SET_FILES_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = '0123456789'\n",
    "for tile in list(annotations.items()):\n",
    "    tile_d = tile[1]\n",
    "    tile_regions = tile_d['regions']\n",
    "    # process this tile if there are annotations for it\n",
    "    if len(tile_regions) > 0:\n",
    "        # get the tile URL\n",
    "        tile_url = tile_d['filename']\n",
    "\n",
    "        # review each feature marked in this tile\n",
    "        for feature_idx,region in enumerate(tile_regions):\n",
    "            # get the feature coordinates\n",
    "            shape_attributes = region['shape_attributes']\n",
    "            x = shape_attributes['x']\n",
    "            y = shape_attributes['y']\n",
    "            w = shape_attributes['width']\n",
    "            h = shape_attributes['height']\n",
    "\n",
    "            # convert to raw data coordinates\n",
    "            data_coords = tile_coords_to_data_coords(tile_url, PIXELS_X, PIXELS_Y, x, y, w, h, 1.0)\n",
    "\n",
    "            # determine the class\n",
    "            region_attributes = region['region_attributes']\n",
    "            charge = int(''.join(c for c in region_attributes['charge'] if c in digits))\n",
    "            feature_class = charge - 2\n",
    "            \n",
    "            if charge >= 2:            \n",
    "                # how many instances to synthesise for this charge\n",
    "                number_of_features_to_synthesise = number_of_features_to_synthesise_for_charge[charge]\n",
    "\n",
    "                # calculate the annotation coordinates for the text file\n",
    "                yolo_x = (x + (w / 2)) / PIXELS_X\n",
    "                yolo_y = (y + (h / 2)) / PIXELS_Y\n",
    "                yolo_w = w / PIXELS_X\n",
    "                yolo_h = h / PIXELS_Y\n",
    "\n",
    "                # add it to the list\n",
    "                feature_coordinates = []\n",
    "                feature_coordinates.append((\"{} {:.6f} {:.6f} {:.6f} {:.6f}\".format(feature_class, yolo_x, yolo_y, yolo_w, yolo_h)))\n",
    "\n",
    "                if number_of_features_to_synthesise > 0:\n",
    "                    # get the raw points for this feature\n",
    "                    db_conn = sqlite3.connect(CONVERTED_DATABASE_NAME)\n",
    "                    raw_points_df = pd.read_sql_query(\"select mz,scan,intensity from frames where frame_id == {} and mz >= {} and mz <= {} and scan >= {} and scan <= {}\".format(data_coords['frame_id'], data_coords['mz_lower'], data_coords['mz_upper'], data_coords['scan_lower'], data_coords['scan_upper']), db_conn)\n",
    "                    db_conn.close()\n",
    "\n",
    "                    # convert the raw points to a tile\n",
    "                    render_synthesised_tile(data_coords['frame_id'], tile_idx, feature_idx, raw_points_df, tile_dir_d, feature_coordinates, number_of_features_to_synthesise)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copying augmented tiles to the training set.\n"
     ]
    }
   ],
   "source": [
    "# copy the synthesised tiles to the training set directory\n",
    "for d in tile_dir_d.values():\n",
    "    augmented_files = glob.glob(\"{}/*.*\".format(d))\n",
    "    print(\"copying augmented tiles to the training set.\")\n",
    "    for fname in augmented_files:\n",
    "        if os.path.isfile(fname):\n",
    "            basename = os.path.basename(fname)\n",
    "            shutil.copyfile('{}/{}'.format(d, basename), '{}/{}'.format(TRAINING_SET_FILES_DIR, basename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "refreshing the train-list file\n"
     ]
    }
   ],
   "source": [
    "# regenerate the training file list\n",
    "training_set_files = glob.glob(\"{}/*.png\".format(TRAINING_SET_FILES_DIR))\n",
    "training_set_augmented_size = len(training_set_files)\n",
    "print(\"refreshing the train-list file\")\n",
    "training_set_l = []\n",
    "for fname in training_set_files:\n",
    "    if os.path.isfile(fname):\n",
    "        basename = os.path.basename(fname)\n",
    "        training_set_l.append('data/peptides/sets/train/{}'.format(basename))\n",
    "df = pd.DataFrame(training_set_l, columns=['filename'])\n",
    "df.to_csv(\"{}/train.txt\".format(TRAINING_SET_BASE_DIR), index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm the labelling of the augmented tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "png_file = glob.glob(\"{}/*.png\".format(TRAINING_SET_FILES_DIR))[10]\n",
    "png_file_base = os.path.splitext(os.path.basename(png_file))[0]\n",
    "txt_file = \"{}/{}.txt\".format(TRAINING_SET_FILES_DIR, png_file_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/Users/darylwilding-mcbride/Documents/Personal/PhD/source/yolo-tile-labelling/training set/sets/train/frame-1939-tile-33-feature-10-intensity-aug-450.png',\n",
       " '/Users/darylwilding-mcbride/Documents/Personal/PhD/source/yolo-tile-labelling/training set/sets/train/frame-1939-tile-33-feature-10-intensity-aug-450.txt')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "png_file, txt_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(txt_file, names=['instance_class','x','y','w','h'], sep=' ', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instance_class</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>w</th>\n",
       "      <th>h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.341758</td>\n",
       "      <td>0.894505</td>\n",
       "      <td>0.041758</td>\n",
       "      <td>0.050549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   instance_class         x         y         w         h\n",
       "0               1  0.341758  0.894505  0.041758  0.050549"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.iloc[0].x * PIXELS_X  # for YOLO, x,y marks the centre of the bounding box\n",
    "y = df.iloc[0].y * PIXELS_Y\n",
    "w = df.iloc[0].w * PIXELS_X\n",
    "h = df.iloc[0].h * PIXELS_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(310.99978, 813.9995499999999, 37.999779999999994, 45.999590000000005)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y,w,h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_img = Image.open(png_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw = ImageDraw.Draw(tile_img)\n",
    "draw.rectangle(xy=[(x-w/2, y-h/2), (x+w/2, y+h/2)], fill=None, outline='green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA44AAAOPCAIAAAALyQhmAAAKq0lEQVR4nO3cPS4FUQCG4UvcQqGxBEuwDFvgigRRI1GIYiqdn1aESFDYgOVYgkYhuX5riWYSJ+c75nnqmZyvfDM5mdEIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABKmqk9AIahG8yhAAA0phvAiQDw12ZrDwAAgN9JVQAAQklVAABCSVUAAEJJVQAAQklVAABCSVUAAEJJVQAAQklVAABCSVUAAEJJVQAAQklVAABCSVUAAEJJVQAAQklVAABCSVVo2Mv2Wu0JAFCQVIWGLVze1Z4AAAVJVQAAQklVAABCSVVI8brv4ikA/CBVIcX8Sb+Lp6+7q4WWAEAIqQqtmj+7rz0BAMqSqgAAhJKqkOLteKP2BADIIlUhxfjwpvYEAMgiVSHF82TS95Vpt15iCQCEkKqQYvH2tu8rHy+fJZYAQAipCineTzf7PX++1ff/VgDQFqkKKeb2rno9/zX1SRWAf06qQqvGB9e1JwBAWVIVAIBQUhUa9rSyU3sCABQkVaFhS48XtScAQEFSFRr2sHxUewIAAK3rBnAiAPw1X1UBAAglVQEACCVVAQAIJVUBAAglVQEACCVVAQAIJVUBAAglVQEACCVVAQAINVd7AAxGV3sAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABD9w0BhyYzbyLeIwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=910x911 at 0x11EFF42B0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tile_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the number of class instances in each set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "SETS_BASE_DIR = '{}/sets'.format(TRAINING_SET_BASE_DIR)\n",
    "TRAIN_SET_DIR = '{}/train'.format(SETS_BASE_DIR)\n",
    "VAL_SET_DIR = '{}/validation'.format(SETS_BASE_DIR)\n",
    "TEST_SET_DIR = '{}/test'.format(SETS_BASE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sets = [TRAIN_SET_DIR, VAL_SET_DIR, TEST_SET_DIR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instances of each class in /Users/darylwilding-mcbride/Documents/Personal/PhD/source/yolo-tile-labelling/training set/sets/train:\n",
      "0    12980\n",
      "1     2242\n",
      "\n",
      "instances of each class in /Users/darylwilding-mcbride/Documents/Personal/PhD/source/yolo-tile-labelling/training set/sets/validation:\n",
      "0    115\n",
      "1      4\n",
      "\n",
      "instances of each class in /Users/darylwilding-mcbride/Documents/Personal/PhD/source/yolo-tile-labelling/training set/sets/test:\n",
      "0    127\n",
      "1      8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for s in sets:\n",
    "    # count the instances for each class in the train set\n",
    "    instances_l = []\n",
    "    training_set_txt_files = glob.glob(\"{}/*.txt\".format(s))\n",
    "    for fname in training_set_txt_files:\n",
    "        df = pd.read_csv(fname, names=['instance_class','x','y','w','h'], sep=' ', header=None)\n",
    "        instances_l.append(df)\n",
    "    instances_df = pd.concat(instances_l, axis=0, sort=False)\n",
    "    print(\"instances of each class in {}:\\n{}\\n\".format(s, instances_df.instance_class.value_counts().to_string()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
